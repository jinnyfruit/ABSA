training_phase start . . .
train_sentiment_analysis
entity property model would be saved at  /home/nlplab/hdd1/2022_korean_AI/JiWoo/ABSA_Code/BASELINE/koBERT/saved_models/category_extraction
polarity model would be saved at  /home/nlplab/hdd1/2022_korean_AI/JiWoo/ABSA_Code/BASELINE/koBERT/saved_models/polarity_classification
loading train data
tokenizing train data
We have added 8 tokens
polarity_data_count:  3194
entity_property_data_count:  59827
polarity_data_count:  6196
entity_property_data_count:  115499
loading model
You are using a model of type electra to instantiate a model of type xlm-roberta. This is not supported for all configurations of models and can yield errors.
Some weights of the model checkpoint at monologg/koelectra-small-v2-discriminator were not used when initializing XLMRobertaModel: ['electra.encoder.layer.11.attention.self.key.weight', 'electra.encoder.layer.11.output.dense.bias', 'electra.encoder.layer.0.attention.self.key.bias', 'electra.encoder.layer.8.output.LayerNorm.weight', 'electra.encoder.layer.6.attention.self.key.weight', 'electra.encoder.layer.0.attention.self.query.bias', 'electra.encoder.layer.9.intermediate.dense.bias', 'electra.encoder.layer.6.attention.self.value.weight', 'electra.encoder.layer.1.attention.self.query.bias', 'electra.encoder.layer.3.output.LayerNorm.bias', 'electra.encoder.layer.6.intermediate.dense.weight', 'electra.encoder.layer.4.attention.output.dense.bias', 'electra.encoder.layer.8.attention.self.query.bias', 'electra.encoder.layer.9.attention.self.key.bias', 'electra.encoder.layer.11.intermediate.dense.weight', 'electra.encoder.layer.4.intermediate.dense.weight', 'electra.encoder.layer.2.attention.output.dense.weight', 'electra.encoder.layer.10.output.LayerNorm.weight', 'electra.encoder.layer.7.attention.self.key.bias', 'electra.encoder.layer.5.intermediate.dense.bias', 'electra.encoder.layer.4.attention.self.key.weight', 'electra.encoder.layer.8.attention.output.dense.weight', 'electra.encoder.layer.6.output.dense.bias', 'electra.encoder.layer.10.attention.self.value.weight', 'electra.encoder.layer.0.attention.output.dense.weight', 'electra.encoder.layer.6.output.LayerNorm.bias', 'electra.embeddings.LayerNorm.weight', 'electra.encoder.layer.1.intermediate.dense.weight', 'electra.encoder.layer.6.attention.self.query.bias', 'electra.encoder.layer.6.intermediate.dense.bias', 'electra.encoder.layer.4.attention.output.dense.weight', 'electra.embeddings.position_embeddings.weight', 'electra.encoder.layer.1.output.LayerNorm.bias', 'electra.encoder.layer.10.attention.self.key.bias', 'electra.encoder.layer.5.output.dense.bias', 'electra.encoder.layer.10.attention.output.LayerNorm.weight', 'electra.embeddings_project.bias', 'electra.encoder.layer.1.attention.output.LayerNorm.bias', 'electra.encoder.layer.6.attention.output.LayerNorm.bias', 'electra.encoder.layer.0.output.LayerNorm.weight', 'electra.encoder.layer.2.attention.self.key.weight', 'electra.encoder.layer.2.attention.output.LayerNorm.bias', 'electra.encoder.layer.5.attention.self.key.bias', 'electra.encoder.layer.7.output.LayerNorm.bias', 'discriminator_predictions.dense_prediction.weight', 'electra.encoder.layer.3.attention.self.query.bias', 'electra.encoder.layer.6.attention.self.value.bias', 'electra.encoder.layer.7.intermediate.dense.weight', 'electra.encoder.layer.5.intermediate.dense.weight', 'electra.encoder.layer.7.attention.self.query.weight', 'electra.encoder.layer.1.attention.self.query.weight', 'electra.encoder.layer.1.attention.output.dense.bias', 'electra.encoder.layer.2.attention.self.value.weight', 'electra.encoder.layer.0.output.dense.bias', 'electra.embeddings.LayerNorm.bias', 'electra.encoder.layer.5.attention.self.key.weight', 'electra.encoder.layer.1.attention.self.value.weight', 'electra.encoder.layer.7.attention.self.value.weight', 'electra.encoder.layer.5.attention.self.query.weight', 'electra.encoder.layer.9.attention.self.value.weight', 'electra.encoder.layer.4.attention.self.value.bias', 'electra.encoder.layer.5.output.LayerNorm.bias', 'electra.encoder.layer.4.output.LayerNorm.bias', 'electra.encoder.layer.11.attention.self.value.bias', 'electra.encoder.layer.11.output.LayerNorm.bias', 'electra.encoder.layer.10.output.LayerNorm.bias', 'electra.encoder.layer.0.attention.self.value.bias', 'electra.encoder.layer.4.output.LayerNorm.weight', 'electra.encoder.layer.2.output.dense.bias', 'electra.encoder.layer.4.attention.self.query.weight', 'electra.encoder.layer.6.attention.output.dense.bias', 'electra.encoder.layer.0.attention.output.LayerNorm.bias', 'electra.encoder.layer.4.attention.output.LayerNorm.bias', 'electra.encoder.layer.10.attention.self.value.bias', 'electra.encoder.layer.0.intermediate.dense.bias', 'electra.encoder.layer.8.attention.self.value.weight', 'electra.encoder.layer.7.attention.self.query.bias', 'electra.encoder.layer.7.output.LayerNorm.weight', 'electra.encoder.layer.7.attention.output.dense.weight', 'electra.encoder.layer.2.attention.output.dense.bias', 'electra.encoder.layer.3.output.LayerNorm.weight', 'electra.encoder.layer.5.attention.self.value.bias', 'electra.encoder.layer.9.output.dense.weight', 'electra.encoder.layer.7.attention.self.key.weight', 'electra.encoder.layer.4.attention.self.key.bias', 'electra.encoder.layer.8.output.LayerNorm.bias', 'discriminator_predictions.dense_prediction.bias', 'electra.embeddings_project.weight', 'electra.encoder.layer.0.attention.output.dense.bias', 'electra.encoder.layer.6.attention.self.query.weight', 'electra.encoder.layer.2.attention.self.query.weight', 'electra.encoder.layer.3.output.dense.bias', 'electra.encoder.layer.8.attention.output.LayerNorm.weight', 'electra.encoder.layer.2.output.LayerNorm.weight', 'electra.encoder.layer.5.output.dense.weight', 'electra.encoder.layer.1.attention.self.value.bias', 'electra.encoder.layer.8.output.dense.bias', 'electra.encoder.layer.8.attention.self.key.weight', 'electra.encoder.layer.11.attention.self.value.weight', 'electra.encoder.layer.6.attention.output.dense.weight', 'electra.encoder.layer.5.output.LayerNorm.weight', 'electra.encoder.layer.9.attention.self.value.bias', 'electra.encoder.layer.7.output.dense.bias', 'electra.encoder.layer.9.attention.output.LayerNorm.bias', 'electra.encoder.layer.10.intermediate.dense.weight', 'electra.encoder.layer.0.intermediate.dense.weight', 'electra.encoder.layer.3.intermediate.dense.weight', 'electra.encoder.layer.11.output.LayerNorm.weight', 'electra.encoder.layer.9.attention.self.key.weight', 'electra.embeddings.word_embeddings.weight', 'electra.encoder.layer.1.attention.output.LayerNorm.weight', 'electra.encoder.layer.4.intermediate.dense.bias', 'electra.encoder.layer.2.attention.output.LayerNorm.weight', 'electra.encoder.layer.9.intermediate.dense.weight', 'electra.encoder.layer.10.intermediate.dense.bias', 'electra.encoder.layer.3.attention.output.LayerNorm.bias', 'electra.encoder.layer.4.output.dense.bias', 'electra.encoder.layer.5.attention.output.dense.bias', 'electra.encoder.layer.0.output.LayerNorm.bias', 'electra.encoder.layer.7.attention.self.value.bias', 'electra.encoder.layer.7.intermediate.dense.bias', 'electra.encoder.layer.3.attention.self.value.weight', 'electra.encoder.layer.9.attention.output.dense.bias', 'electra.encoder.layer.5.attention.self.query.bias', 'electra.encoder.layer.6.attention.self.key.bias', 'electra.encoder.layer.1.attention.self.key.bias', 'electra.encoder.layer.8.attention.output.dense.bias', 'electra.encoder.layer.5.attention.output.LayerNorm.weight', 'electra.encoder.layer.9.attention.self.query.bias', 'electra.encoder.layer.9.output.LayerNorm.weight', 'electra.encoder.layer.11.attention.self.query.bias', 'electra.encoder.layer.11.intermediate.dense.bias', 'electra.encoder.layer.4.attention.self.value.weight', 'electra.encoder.layer.5.attention.output.dense.weight', 'electra.encoder.layer.7.output.dense.weight', 'electra.encoder.layer.8.attention.self.value.bias', 'electra.encoder.layer.7.attention.output.LayerNorm.weight', 'discriminator_predictions.dense.bias', 'electra.encoder.layer.1.attention.output.dense.weight', 'electra.encoder.layer.1.attention.self.key.weight', 'electra.encoder.layer.11.attention.self.query.weight', 'electra.encoder.layer.11.attention.output.LayerNorm.bias', 'electra.encoder.layer.7.attention.output.dense.bias', 'electra.encoder.layer.0.attention.output.LayerNorm.weight', 'electra.encoder.layer.2.intermediate.dense.bias', 'electra.encoder.layer.10.attention.output.dense.weight', 'electra.encoder.layer.2.attention.self.key.bias', 'electra.encoder.layer.8.intermediate.dense.weight', 'electra.encoder.layer.6.attention.output.LayerNorm.weight', 'electra.encoder.layer.10.output.dense.bias', 'electra.encoder.layer.0.attention.self.key.weight', 'electra.encoder.layer.3.output.dense.weight', 'electra.encoder.layer.4.attention.self.query.bias', 'electra.encoder.layer.2.attention.self.query.bias', 'electra.encoder.layer.10.attention.output.LayerNorm.bias', 'electra.encoder.layer.10.output.dense.weight', 'electra.encoder.layer.6.output.LayerNorm.weight', 'electra.encoder.layer.2.output.dense.weight', 'electra.encoder.layer.8.attention.self.query.weight', 'electra.encoder.layer.3.attention.output.dense.weight', 'electra.encoder.layer.3.attention.self.key.bias', 'electra.encoder.layer.8.intermediate.dense.bias', 'electra.encoder.layer.10.attention.self.key.weight', 'electra.encoder.layer.11.output.dense.weight', 'discriminator_predictions.dense.weight', 'electra.encoder.layer.11.attention.output.dense.bias', 'electra.encoder.layer.4.attention.output.LayerNorm.weight', 'electra.encoder.layer.2.output.LayerNorm.bias', 'electra.encoder.layer.4.output.dense.weight', 'electra.encoder.layer.8.attention.self.key.bias', 'electra.encoder.layer.1.output.dense.weight', 'electra.encoder.layer.11.attention.self.key.bias', 'electra.encoder.layer.1.intermediate.dense.bias', 'electra.encoder.layer.3.attention.self.key.weight', 'electra.encoder.layer.8.attention.output.LayerNorm.bias', 'electra.encoder.layer.0.attention.self.query.weight', 'electra.encoder.layer.2.attention.self.value.bias', 'electra.encoder.layer.5.attention.self.value.weight', 'electra.encoder.layer.0.attention.self.value.weight', 'electra.encoder.layer.5.attention.output.LayerNorm.bias', 'electra.encoder.layer.1.output.dense.bias', 'electra.embeddings.token_type_embeddings.weight', 'electra.encoder.layer.10.attention.output.dense.bias', 'electra.encoder.layer.3.attention.output.LayerNorm.weight', 'electra.encoder.layer.9.attention.self.query.weight', 'electra.encoder.layer.9.attention.output.LayerNorm.weight', 'electra.encoder.layer.10.attention.self.query.bias', 'electra.encoder.layer.9.output.dense.bias', 'electra.encoder.layer.11.attention.output.dense.weight', 'electra.encoder.layer.3.attention.self.value.bias', 'electra.encoder.layer.7.attention.output.LayerNorm.bias', 'electra.encoder.layer.9.output.LayerNorm.bias', 'electra.encoder.layer.9.attention.output.dense.weight', 'electra.encoder.layer.3.intermediate.dense.bias', 'electra.encoder.layer.0.output.dense.weight', 'electra.encoder.layer.2.intermediate.dense.weight', 'electra.encoder.layer.3.attention.output.dense.bias', 'electra.encoder.layer.1.output.LayerNorm.weight', 'electra.encoder.layer.8.output.dense.weight', 'electra.encoder.layer.6.output.dense.weight', 'electra.encoder.layer.3.attention.self.query.weight', 'electra.encoder.layer.11.attention.output.LayerNorm.weight', 'electra.encoder.layer.10.attention.self.query.weight']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at monologg/koelectra-small-v2-discriminator and are newly initialized: ['encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'pooler.dense.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.11.attention.self.query.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.7.attention.self.key.bias', 'pooler.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.1.intermediate.dense.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.8.attention.self.value.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.11.intermediate.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
You are using a model of type electra to instantiate a model of type xlm-roberta. This is not supported for all configurations of models and can yield errors.
Some weights of the model checkpoint at monologg/koelectra-small-v2-discriminator were not used when initializing XLMRobertaModel: ['electra.encoder.layer.11.attention.self.key.weight', 'electra.encoder.layer.11.output.dense.bias', 'electra.encoder.layer.0.attention.self.key.bias', 'electra.encoder.layer.8.output.LayerNorm.weight', 'electra.encoder.layer.6.attention.self.key.weight', 'electra.encoder.layer.0.attention.self.query.bias', 'electra.encoder.layer.9.intermediate.dense.bias', 'electra.encoder.layer.6.attention.self.value.weight', 'electra.encoder.layer.1.attention.self.query.bias', 'electra.encoder.layer.3.output.LayerNorm.bias', 'electra.encoder.layer.6.intermediate.dense.weight', 'electra.encoder.layer.4.attention.output.dense.bias', 'electra.encoder.layer.8.attention.self.query.bias', 'electra.encoder.layer.9.attention.self.key.bias', 'electra.encoder.layer.11.intermediate.dense.weight', 'electra.encoder.layer.4.intermediate.dense.weight', 'electra.encoder.layer.2.attention.output.dense.weight', 'electra.encoder.layer.10.output.LayerNorm.weight', 'electra.encoder.layer.7.attention.self.key.bias', 'electra.encoder.layer.5.intermediate.dense.bias', 'electra.encoder.layer.4.attention.self.key.weight', 'electra.encoder.layer.8.attention.output.dense.weight', 'electra.encoder.layer.6.output.dense.bias', 'electra.encoder.layer.10.attention.self.value.weight', 'electra.encoder.layer.0.attention.output.dense.weight', 'electra.encoder.layer.6.output.LayerNorm.bias', 'electra.embeddings.LayerNorm.weight', 'electra.encoder.layer.1.intermediate.dense.weight', 'electra.encoder.layer.6.attention.self.query.bias', 'electra.encoder.layer.6.intermediate.dense.bias', 'electra.encoder.layer.4.attention.output.dense.weight', 'electra.embeddings.position_embeddings.weight', 'electra.encoder.layer.1.output.LayerNorm.bias', 'electra.encoder.layer.10.attention.self.key.bias', 'electra.encoder.layer.5.output.dense.bias', 'electra.encoder.layer.10.attention.output.LayerNorm.weight', 'electra.embeddings_project.bias', 'electra.encoder.layer.1.attention.output.LayerNorm.bias', 'electra.encoder.layer.6.attention.output.LayerNorm.bias', 'electra.encoder.layer.0.output.LayerNorm.weight', 'electra.encoder.layer.2.attention.self.key.weight', 'electra.encoder.layer.2.attention.output.LayerNorm.bias', 'electra.encoder.layer.5.attention.self.key.bias', 'electra.encoder.layer.7.output.LayerNorm.bias', 'discriminator_predictions.dense_prediction.weight', 'electra.encoder.layer.3.attention.self.query.bias', 'electra.encoder.layer.6.attention.self.value.bias', 'electra.encoder.layer.7.intermediate.dense.weight', 'electra.encoder.layer.5.intermediate.dense.weight', 'electra.encoder.layer.7.attention.self.query.weight', 'electra.encoder.layer.1.attention.self.query.weight', 'electra.encoder.layer.1.attention.output.dense.bias', 'electra.encoder.layer.2.attention.self.value.weight', 'electra.encoder.layer.0.output.dense.bias', 'electra.embeddings.LayerNorm.bias', 'electra.encoder.layer.5.attention.self.key.weight', 'electra.encoder.layer.1.attention.self.value.weight', 'electra.encoder.layer.7.attention.self.value.weight', 'electra.encoder.layer.5.attention.self.query.weight', 'electra.encoder.layer.9.attention.self.value.weight', 'electra.encoder.layer.4.attention.self.value.bias', 'electra.encoder.layer.5.output.LayerNorm.bias', 'electra.encoder.layer.4.output.LayerNorm.bias', 'electra.encoder.layer.11.attention.self.value.bias', 'electra.encoder.layer.11.output.LayerNorm.bias', 'electra.encoder.layer.10.output.LayerNorm.bias', 'electra.encoder.layer.0.attention.self.value.bias', 'electra.encoder.layer.4.output.LayerNorm.weight', 'electra.encoder.layer.2.output.dense.bias', 'electra.encoder.layer.4.attention.self.query.weight', 'electra.encoder.layer.6.attention.output.dense.bias', 'electra.encoder.layer.0.attention.output.LayerNorm.bias', 'electra.encoder.layer.4.attention.output.LayerNorm.bias', 'electra.encoder.layer.10.attention.self.value.bias', 'electra.encoder.layer.0.intermediate.dense.bias', 'electra.encoder.layer.8.attention.self.value.weight', 'electra.encoder.layer.7.attention.self.query.bias', 'electra.encoder.layer.7.output.LayerNorm.weight', 'electra.encoder.layer.7.attention.output.dense.weight', 'electra.encoder.layer.2.attention.output.dense.bias', 'electra.encoder.layer.3.output.LayerNorm.weight', 'electra.encoder.layer.5.attention.self.value.bias', 'electra.encoder.layer.9.output.dense.weight', 'electra.encoder.layer.7.attention.self.key.weight', 'electra.encoder.layer.4.attention.self.key.bias', 'electra.encoder.layer.8.output.LayerNorm.bias', 'discriminator_predictions.dense_prediction.bias', 'electra.embeddings_project.weight', 'electra.encoder.layer.0.attention.output.dense.bias', 'electra.encoder.layer.6.attention.self.query.weight', 'electra.encoder.layer.2.attention.self.query.weight', 'electra.encoder.layer.3.output.dense.bias', 'electra.encoder.layer.8.attention.output.LayerNorm.weight', 'electra.encoder.layer.2.output.LayerNorm.weight', 'electra.encoder.layer.5.output.dense.weight', 'electra.encoder.layer.1.attention.self.value.bias', 'electra.encoder.layer.8.output.dense.bias', 'electra.encoder.layer.8.attention.self.key.weight', 'electra.encoder.layer.11.attention.self.value.weight', 'electra.encoder.layer.6.attention.output.dense.weight', 'electra.encoder.layer.5.output.LayerNorm.weight', 'electra.encoder.layer.9.attention.self.value.bias', 'electra.encoder.layer.7.output.dense.bias', 'electra.encoder.layer.9.attention.output.LayerNorm.bias', 'electra.encoder.layer.10.intermediate.dense.weight', 'electra.encoder.layer.0.intermediate.dense.weight', 'electra.encoder.layer.3.intermediate.dense.weight', 'electra.encoder.layer.11.output.LayerNorm.weight', 'electra.encoder.layer.9.attention.self.key.weight', 'electra.embeddings.word_embeddings.weight', 'electra.encoder.layer.1.attention.output.LayerNorm.weight', 'electra.encoder.layer.4.intermediate.dense.bias', 'electra.encoder.layer.2.attention.output.LayerNorm.weight', 'electra.encoder.layer.9.intermediate.dense.weight', 'electra.encoder.layer.10.intermediate.dense.bias', 'electra.encoder.layer.3.attention.output.LayerNorm.bias', 'electra.encoder.layer.4.output.dense.bias', 'electra.encoder.layer.5.attention.output.dense.bias', 'electra.encoder.layer.0.output.LayerNorm.bias', 'electra.encoder.layer.7.attention.self.value.bias', 'electra.encoder.layer.7.intermediate.dense.bias', 'electra.encoder.layer.3.attention.self.value.weight', 'electra.encoder.layer.9.attention.output.dense.bias', 'electra.encoder.layer.5.attention.self.query.bias', 'electra.encoder.layer.6.attention.self.key.bias', 'electra.encoder.layer.1.attention.self.key.bias', 'electra.encoder.layer.8.attention.output.dense.bias', 'electra.encoder.layer.5.attention.output.LayerNorm.weight', 'electra.encoder.layer.9.attention.self.query.bias', 'electra.encoder.layer.9.output.LayerNorm.weight', 'electra.encoder.layer.11.attention.self.query.bias', 'electra.encoder.layer.11.intermediate.dense.bias', 'electra.encoder.layer.4.attention.self.value.weight', 'electra.encoder.layer.5.attention.output.dense.weight', 'electra.encoder.layer.7.output.dense.weight', 'electra.encoder.layer.8.attention.self.value.bias', 'electra.encoder.layer.7.attention.output.LayerNorm.weight', 'discriminator_predictions.dense.bias', 'electra.encoder.layer.1.attention.output.dense.weight', 'electra.encoder.layer.1.attention.self.key.weight', 'electra.encoder.layer.11.attention.self.query.weight', 'electra.encoder.layer.11.attention.output.LayerNorm.bias', 'electra.encoder.layer.7.attention.output.dense.bias', 'electra.encoder.layer.0.attention.output.LayerNorm.weight', 'electra.encoder.layer.2.intermediate.dense.bias', 'electra.encoder.layer.10.attention.output.dense.weight', 'electra.encoder.layer.2.attention.self.key.bias', 'electra.encoder.layer.8.intermediate.dense.weight', 'electra.encoder.layer.6.attention.output.LayerNorm.weight', 'electra.encoder.layer.10.output.dense.bias', 'electra.encoder.layer.0.attention.self.key.weight', 'electra.encoder.layer.3.output.dense.weight', 'electra.encoder.layer.4.attention.self.query.bias', 'electra.encoder.layer.2.attention.self.query.bias', 'electra.encoder.layer.10.attention.output.LayerNorm.bias', 'electra.encoder.layer.10.output.dense.weight', 'electra.encoder.layer.6.output.LayerNorm.weight', 'electra.encoder.layer.2.output.dense.weight', 'electra.encoder.layer.8.attention.self.query.weight', 'electra.encoder.layer.3.attention.output.dense.weight', 'electra.encoder.layer.3.attention.self.key.bias', 'electra.encoder.layer.8.intermediate.dense.bias', 'electra.encoder.layer.10.attention.self.key.weight', 'electra.encoder.layer.11.output.dense.weight', 'discriminator_predictions.dense.weight', 'electra.encoder.layer.11.attention.output.dense.bias', 'electra.encoder.layer.4.attention.output.LayerNorm.weight', 'electra.encoder.layer.2.output.LayerNorm.bias', 'electra.encoder.layer.4.output.dense.weight', 'electra.encoder.layer.8.attention.self.key.bias', 'electra.encoder.layer.1.output.dense.weight', 'electra.encoder.layer.11.attention.self.key.bias', 'electra.encoder.layer.1.intermediate.dense.bias', 'electra.encoder.layer.3.attention.self.key.weight', 'electra.encoder.layer.8.attention.output.LayerNorm.bias', 'electra.encoder.layer.0.attention.self.query.weight', 'electra.encoder.layer.2.attention.self.value.bias', 'electra.encoder.layer.5.attention.self.value.weight', 'electra.encoder.layer.0.attention.self.value.weight', 'electra.encoder.layer.5.attention.output.LayerNorm.bias', 'electra.encoder.layer.1.output.dense.bias', 'electra.embeddings.token_type_embeddings.weight', 'electra.encoder.layer.10.attention.output.dense.bias', 'electra.encoder.layer.3.attention.output.LayerNorm.weight', 'electra.encoder.layer.9.attention.self.query.weight', 'electra.encoder.layer.9.attention.output.LayerNorm.weight', 'electra.encoder.layer.10.attention.self.query.bias', 'electra.encoder.layer.9.output.dense.bias', 'electra.encoder.layer.11.attention.output.dense.weight', 'electra.encoder.layer.3.attention.self.value.bias', 'electra.encoder.layer.7.attention.output.LayerNorm.bias', 'electra.encoder.layer.9.output.LayerNorm.bias', 'electra.encoder.layer.9.attention.output.dense.weight', 'electra.encoder.layer.3.intermediate.dense.bias', 'electra.encoder.layer.0.output.dense.weight', 'electra.encoder.layer.2.intermediate.dense.weight', 'electra.encoder.layer.3.attention.output.dense.bias', 'electra.encoder.layer.1.output.LayerNorm.weight', 'electra.encoder.layer.8.output.dense.weight', 'electra.encoder.layer.6.output.dense.weight', 'electra.encoder.layer.3.attention.self.query.weight', 'electra.encoder.layer.11.attention.output.LayerNorm.weight', 'electra.encoder.layer.10.attention.self.query.weight']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at monologg/koelectra-small-v2-discriminator and are newly initialized: ['encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'pooler.dense.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.11.attention.self.query.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.7.attention.self.key.bias', 'pooler.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.1.intermediate.dense.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.8.attention.self.value.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.11.intermediate.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/nlplab/anaconda3/envs/jiwoo/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
Epoch:   0%|                                                                                                                                       | 0/10 [00:00<?, ?it/s]
end loading
Entity_Property_Epoch:  1
Average train loss: 0.16849279931662509
[3002, 55672]
[0, 55672]
[0.0, 1.0]
accuracy:  0.9488359409619253
macro_accuracy:  0.3333333333333333
f1_score:  [0.         0.97374635]
f1_score_micro:  0.9488359409619253
f1_score_macro:  0.48687317440050376
Entity_polarity_Epoch:  1
Average train loss: 0.2448099597473629
[2921, 27, 54]
[2921, 0, 0]
[1.0, 0.0, 0.0]
accuracy:  0.9730179880079947
macro_accuracy:  0.3333333333333333
f1_score:  [0.9863245 0.        0.       ]
f1_score_micro:  0.9730179880079947

Epoch:  10%|███████████▉                                                                                                           | 1/10 [2:58:04<26:42:37, 10684.16s/it]
Entity_Property_Epoch:  2
Average train loss: 0.1481209736632663
[3002, 55672]
[349, 55567]
[0.11625582944703532, 0.9981139531541888]
accuracy:  0.9529945120496301
macro_accuracy:  0.37145659420040805
f1_score:  [0.20196759 0.97578408]
f1_score_micro:  0.9529945120496301
f1_score_macro:  0.5888758343674515
Entity_polarity_Epoch:  2
Average train loss: 0.22660687604220583
[2921, 27, 54]
[2921, 0, 0]
[1.0, 0.0, 0.0]
accuracy:  0.9730179880079947
macro_accuracy:  0.3333333333333333
f1_score:  [0.9863245 0.        0.       ]
f1_score_micro:  0.9730179880079947

Epoch:  20%|███████████████████████▊                                                                                               | 2/10 [5:59:07<23:58:35, 10789.38s/it]
Entity_Property_Epoch:  3
Average train loss: 0.13280467012809083
[3002, 55672]
[1140, 55210]
[0.379746835443038, 0.9917013938784308]
accuracy:  0.9603913147220234
macro_accuracy:  0.45714940977382296
f1_score:  [0.49522155 0.97938693]
f1_score_micro:  0.9603913147220234
f1_score_macro:  0.7373042380813614
Entity_polarity_Epoch:  3

Epoch:  30%|███████████████████████████████████▍                                                                                  | 3/10 [10:36:14<26:09:45, 13455.08s/it]
[2921, 27, 54]
[2921, 0, 0]
[1.0, 0.0, 0.0]
accuracy:  0.9730179880079947
macro_accuracy:  0.3333333333333333
f1_score:  [0.9863245 0.        0.       ]
f1_score_micro:  0.9730179880079947
f1_score_macro:  0.32877483257358325
Entity_Property_Epoch:  4
Average train loss: 0.12056172326169341
[3002, 55672]
[1106, 55248]
[0.3684210526315789, 0.9923839632131053]
accuracy:  0.9604594880185431
macro_accuracy:  0.4536016719482281
f1_score:  [0.48808473 0.97943554]
f1_score_micro:  0.9604594880185431
f1_score_macro:  0.7337601359305916
Entity_polarity_Epoch:  4
Average train loss: 0.1607569170068018
[2921, 27, 54]
[2915, 0, 2]
[0.9979459089352961, 0.0, 0.037037037037037035]
accuracy:  0.9716855429713525
macro_accuracy:  0.34499431532411107
f1_score:  [0.98612991 0.         0.06153846]
f1_score_micro:  0.9716855429713525

Epoch:  40%|███████████████████████████████████████████████▏                                                                      | 4/10 [13:38:46<20:46:40, 12466.72s/it]
Entity_Property_Epoch:  5
Average train loss: 0.11151838469176334
[3002, 55672]
[1265, 55198]
[0.4213857428381079, 0.991485845667481]
accuracy:  0.9623172103487064
macro_accuracy:  0.47095719616852966
f1_score:  [0.53364269 0.98036534]
f1_score_micro:  0.9623172103487064
f1_score_macro:  0.7570040164119645
Entity_polarity_Epoch:  5

Epoch:  50%|███████████████████████████████████████████████████████████                                                           | 5/10 [16:33:31<16:19:21, 11752.30s/it]
[2921, 27, 54]
[2884, 6, 8]
[0.9873331051009928, 0.2222222222222222, 0.14814814814814814]
accuracy:  0.9653564290473018
macro_accuracy:  0.4525678251571211
f1_score:  [0.98379669 0.27272727 0.16494845]
f1_score_micro:  0.9653564290473018
f1_score_macro:  0.4738241391497615
Entity_Property_Epoch:  6
Average train loss: 0.10583280980683625
[3002, 55672]
[1309, 55149]
[0.43604263824117256, 0.990605690472769]
accuracy:  0.9622319937280567
macro_accuracy:  0.4755494429046472
f1_score:  [0.54158047 0.98030467]
f1_score_micro:  0.9622319937280567
f1_score_macro:  0.7609425724276531
Entity_polarity_Epoch:  6
Average train loss: 0.1013628436572617
[2921, 27, 54]
[2910, 1, 3]
[0.9962341663813763, 0.037037037037037035, 0.05555555555555555]
accuracy:  0.9706862091938707
macro_accuracy:  0.36294225299132293
f1_score:  [0.9861064  0.06896552 0.08219178]
f1_score_micro:  0.9706862091938707

Epoch:  60%|██████████████████████████████████████████████████████████████████████▊                                               | 6/10 [19:35:19<12:44:21, 11465.33s/it]
Entity_Property_Epoch:  7
Average train loss: 0.09978636807740221
[3002, 55672]
[1257, 55191]
[0.41872085276482346, 0.9913601092110935]
accuracy:  0.9620615604867573
macro_accuracy:  0.4700269873253056
f1_score:  [0.53037975 0.98023231]
f1_score_micro:  0.9620615604867573
f1_score_macro:  0.7553060285754367
Entity_polarity_Epoch:  7
Average train loss: 0.08730016899935436
[2921, 27, 54]
[2916, 1, 1]
[0.9982882574460801, 0.037037037037037035, 0.018518518518518517]
accuracy:  0.972018654230513
macro_accuracy:  0.35128127100054524
f1_score:  [0.98663509 0.06896552 0.03125   ]
f1_score_micro:  0.972018654230513

Epoch:  70%|███████████████████████████████████████████████████████████████████████████████████▎                                   | 7/10 [22:34:02<9:21:07, 11222.51s/it]
Entity_Property_Epoch:  8
Average train loss: 0.09540196020229422
[3002, 55672]
[1401, 55076]
[0.46668887408394405, 0.9892944388561575]
accuracy:  0.9625558168865256
macro_accuracy:  0.4853277709800339
f1_score:  [0.5605121  0.98044486]
f1_score_micro:  0.9625558168865256
f1_score_macro:  0.7704784830965962
Entity_polarity_Epoch:  8
Average train loss: 0.08069942328438628
[2921, 27, 54]
[2896, 7, 4]
[0.9914412872304006, 0.25925925925925924, 0.07407407407407407]
accuracy:  0.9683544303797469
macro_accuracy:  0.4415915401879113
f1_score:  [0.98469908 0.30434783 0.10526316]
f1_score_micro:  0.9683544303797469

Epoch:  80%|███████████████████████████████████████████████████████████████████████████████████████████████▏                       | 8/10 [25:42:04<6:14:42, 11241.34s/it]
Entity_Property_Epoch:  9
Average train loss: 0.09150765697482287
[3002, 55672]
[1320, 55164]
[0.4397068620919387, 0.9908751257364564]
accuracy:  0.9626751201554351
macro_accuracy:  0.4768606626094651
f1_score:  [0.54658385 0.98053645]
f1_score_micro:  0.9626751201554351
f1_score_macro:  0.763560149216705
Entity_polarity_Epoch:  9

Epoch:  90%|███████████████████████████████████████████████████████████████████████████████████████████████████████████            | 9/10 [28:49:42<3:07:26, 11246.64s/it]
[2921, 27, 54]
[2900, 6, 5]
[0.9928106812735364, 0.2222222222222222, 0.09259259259259259]
accuracy:  0.9696868754163891
macro_accuracy:  0.4358751653627837
f1_score:  [0.98505435 0.30769231 0.12987013]
f1_score_micro:  0.969686875416389
f1_score_macro:  0.47420559512950816
Entity_Property_Epoch:  10
Average train loss: 0.08702072661323798
[3002, 55672]
[1290, 55197]
[0.4297135243171219, 0.9914678833165684]
accuracy:  0.962726250127825
macro_accuracy:  0.4737271358778968
f1_score:  [0.54122089 0.98057399]
f1_score_micro:  0.962726250127825
f1_score_macro:  0.7608974401866779
Entity_polarity_Epoch:  10
Average train loss: 0.06280637921299785
[2921, 27, 54]
[2899, 6, 6]
[0.9924683327627525, 0.2222222222222222, 0.1111111111111111]
accuracy:  0.9696868754163891
macro_accuracy:  0.44193388869869527
f1_score:  [0.98521665 0.30769231 0.15      ]
f1_score_micro:  0.969686875416389
f1_score_macro:  0.48096965339955994

Epoch: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [33:49:09<00:00, 12174.93s/it]