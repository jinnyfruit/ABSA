training_phase start . . .
train_sentiment_analysis
entity property model would be saved at  /home/nlplab/Devlopment/2022_korean_AI/JiWoo/ABSA_Code/BASELINE/koBERT/saved_models/category_extraction
polarity model would be saved at  /home/nlplab/Devlopment/2022_korean_AI/JiWoo/ABSA_Code/BASELINE/koBERT/saved_models/polarity_classification
loading train data
tokenizing train data
We have added 8 tokens
polarity_data_count:  3194
entity_property_data_count:  59827
polarity_data_count:  6196
entity_property_data_count:  115499
loading model
You are using a model of type electra to instantiate a model of type xlm-roberta. This is not supported for all configurations of models and can yield errors.
Some weights of the model checkpoint at monologg/koelectra-small-v2-discriminator were not used when initializing XLMRobertaModel: ['electra.encoder.layer.8.attention.self.key.weight', 'electra.encoder.layer.9.intermediate.dense.bias', 'electra.encoder.layer.6.output.LayerNorm.bias', 'electra.encoder.layer.1.output.dense.weight', 'electra.encoder.layer.10.attention.output.dense.weight', 'electra.embeddings.position_embeddings.weight', 'electra.encoder.layer.11.attention.self.query.bias', 'electra.encoder.layer.9.attention.self.value.weight', 'electra.encoder.layer.9.output.dense.bias', 'electra.encoder.layer.8.attention.output.dense.weight', 'electra.encoder.layer.8.output.dense.weight', 'electra.encoder.layer.1.attention.self.value.weight', 'electra.encoder.layer.11.attention.self.query.weight', 'electra.encoder.layer.10.output.LayerNorm.weight', 'electra.encoder.layer.7.output.LayerNorm.bias', 'electra.encoder.layer.8.intermediate.dense.bias', 'electra.encoder.layer.0.output.dense.bias', 'electra.encoder.layer.0.attention.output.dense.bias', 'electra.encoder.layer.2.attention.self.value.bias', 'electra.encoder.layer.4.attention.self.value.weight', 'electra.encoder.layer.6.attention.output.LayerNorm.bias', 'electra.encoder.layer.9.attention.output.LayerNorm.bias', 'electra.encoder.layer.5.attention.self.key.weight', 'electra.encoder.layer.2.attention.output.LayerNorm.bias', 'electra.encoder.layer.1.intermediate.dense.weight', 'electra.encoder.layer.6.intermediate.dense.bias', 'electra.encoder.layer.0.attention.self.query.bias', 'electra.encoder.layer.11.attention.output.LayerNorm.bias', 'electra.encoder.layer.0.attention.self.query.weight', 'electra.encoder.layer.0.attention.output.LayerNorm.weight', 'electra.encoder.layer.5.attention.self.value.weight', 'electra.encoder.layer.11.attention.self.value.weight', 'electra.embeddings.LayerNorm.bias', 'electra.encoder.layer.9.attention.output.LayerNorm.weight', 'electra.encoder.layer.10.output.dense.weight', 'electra.encoder.layer.5.intermediate.dense.bias', 'electra.encoder.layer.3.output.LayerNorm.bias', 'electra.encoder.layer.5.attention.self.value.bias', 'electra.encoder.layer.5.output.LayerNorm.bias', 'electra.encoder.layer.4.attention.output.LayerNorm.weight', 'electra.encoder.layer.0.intermediate.dense.weight', 'electra.encoder.layer.3.attention.self.value.bias', 'electra.encoder.layer.8.attention.self.value.weight', 'electra.embeddings.token_type_embeddings.weight', 'electra.encoder.layer.7.output.dense.bias', 'electra.encoder.layer.10.attention.self.query.weight', 'electra.encoder.layer.10.attention.self.query.bias', 'electra.encoder.layer.4.attention.self.query.weight', 'electra.encoder.layer.4.attention.self.query.bias', 'electra.encoder.layer.0.output.LayerNorm.bias', 'electra.encoder.layer.9.attention.output.dense.weight', 'electra.encoder.layer.2.attention.self.value.weight', 'electra.encoder.layer.5.attention.self.query.bias', 'electra.encoder.layer.10.attention.output.LayerNorm.bias', 'electra.encoder.layer.7.attention.output.dense.bias', 'electra.encoder.layer.9.intermediate.dense.weight', 'electra.encoder.layer.1.attention.self.key.weight', 'electra.encoder.layer.3.output.dense.bias', 'electra.encoder.layer.2.intermediate.dense.bias', 'electra.encoder.layer.11.attention.self.value.bias', 'electra.encoder.layer.4.intermediate.dense.bias', 'electra.encoder.layer.0.attention.self.value.weight', 'electra.encoder.layer.2.output.LayerNorm.bias', 'electra.encoder.layer.6.attention.self.value.bias', 'electra.encoder.layer.5.attention.output.dense.bias', 'electra.encoder.layer.3.output.LayerNorm.weight', 'electra.encoder.layer.10.attention.self.key.weight', 'electra.encoder.layer.10.output.dense.bias', 'electra.encoder.layer.8.attention.self.query.bias', 'electra.encoder.layer.3.attention.self.query.bias', 'electra.encoder.layer.9.attention.self.value.bias', 'electra.encoder.layer.8.attention.output.dense.bias', 'electra.encoder.layer.10.attention.self.value.weight', 'electra.encoder.layer.6.attention.self.value.weight', 'electra.encoder.layer.1.attention.output.dense.bias', 'electra.encoder.layer.5.output.dense.weight', 'electra.encoder.layer.7.output.LayerNorm.weight', 'electra.embeddings_project.weight', 'electra.encoder.layer.5.attention.output.LayerNorm.weight', 'electra.encoder.layer.0.attention.self.key.bias', 'electra.encoder.layer.6.attention.self.query.weight', 'electra.encoder.layer.1.attention.output.LayerNorm.weight', 'electra.encoder.layer.3.attention.self.key.bias', 'electra.encoder.layer.2.attention.self.query.bias', 'electra.encoder.layer.6.attention.self.key.weight', 'electra.encoder.layer.4.output.dense.bias', 'electra.encoder.layer.7.attention.self.key.weight', 'electra.encoder.layer.11.intermediate.dense.bias', 'electra.encoder.layer.9.attention.self.key.weight', 'electra.encoder.layer.1.attention.output.LayerNorm.bias', 'electra.encoder.layer.3.attention.output.dense.bias', 'electra.encoder.layer.4.attention.self.value.bias', 'electra.encoder.layer.5.output.dense.bias', 'electra.encoder.layer.1.output.LayerNorm.bias', 'electra.encoder.layer.2.output.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'electra.encoder.layer.1.output.dense.bias', 'electra.encoder.layer.2.intermediate.dense.weight', 'electra.encoder.layer.0.attention.self.value.bias', 'electra.encoder.layer.4.attention.self.key.bias', 'electra.encoder.layer.0.attention.output.LayerNorm.bias', 'electra.encoder.layer.7.attention.self.query.bias', 'electra.encoder.layer.5.attention.self.query.weight', 'electra.encoder.layer.7.attention.self.key.bias', 'electra.encoder.layer.6.output.dense.weight', 'electra.encoder.layer.8.attention.self.key.bias', 'electra.encoder.layer.4.output.LayerNorm.bias', 'electra.encoder.layer.6.output.LayerNorm.weight', 'discriminator_predictions.dense_prediction.bias', 'electra.encoder.layer.3.attention.self.query.weight', 'electra.encoder.layer.9.attention.self.key.bias', 'electra.encoder.layer.5.attention.output.LayerNorm.bias', 'electra.encoder.layer.4.output.dense.weight', 'electra.encoder.layer.7.attention.self.value.weight', 'electra.encoder.layer.11.output.dense.bias', 'electra.encoder.layer.3.attention.output.LayerNorm.weight', 'electra.encoder.layer.8.attention.output.LayerNorm.bias', 'electra.encoder.layer.8.output.LayerNorm.weight', 'electra.encoder.layer.4.output.LayerNorm.weight', 'electra.encoder.layer.9.output.dense.weight', 'electra.encoder.layer.9.attention.self.query.bias', 'electra.embeddings.word_embeddings.weight', 'electra.encoder.layer.5.attention.output.dense.weight', 'electra.encoder.layer.10.intermediate.dense.weight', 'electra.encoder.layer.4.attention.output.dense.weight', 'electra.encoder.layer.7.attention.self.value.bias', 'electra.encoder.layer.11.output.LayerNorm.weight', 'electra.encoder.layer.11.attention.output.dense.bias', 'electra.encoder.layer.0.attention.output.dense.weight', 'electra.encoder.layer.0.output.dense.weight', 'electra.encoder.layer.2.attention.self.query.weight', 'electra.encoder.layer.9.attention.output.dense.bias', 'electra.encoder.layer.4.attention.self.key.weight', 'electra.encoder.layer.6.attention.self.key.bias', 'electra.encoder.layer.1.attention.self.query.weight', 'electra.encoder.layer.2.output.LayerNorm.weight', 'electra.encoder.layer.1.output.LayerNorm.weight', 'discriminator_predictions.dense.weight', 'electra.encoder.layer.11.output.dense.weight', 'electra.encoder.layer.5.intermediate.dense.weight', 'electra.encoder.layer.7.attention.output.dense.weight', 'electra.encoder.layer.0.output.LayerNorm.weight', 'electra.encoder.layer.9.attention.self.query.weight', 'electra.encoder.layer.11.output.LayerNorm.bias', 'electra.encoder.layer.3.intermediate.dense.bias', 'discriminator_predictions.dense.bias', 'electra.encoder.layer.7.intermediate.dense.bias', 'electra.encoder.layer.2.output.dense.weight', 'electra.encoder.layer.3.attention.output.dense.weight', 'electra.encoder.layer.1.attention.self.value.bias', 'electra.encoder.layer.2.attention.output.LayerNorm.weight', 'electra.encoder.layer.2.attention.self.key.weight', 'electra.encoder.layer.9.output.LayerNorm.bias', 'electra.encoder.layer.1.attention.self.query.bias', 'electra.encoder.layer.3.attention.self.value.weight', 'electra.encoder.layer.0.intermediate.dense.bias', 'electra.encoder.layer.7.output.dense.weight', 'electra.encoder.layer.6.attention.self.query.bias', 'electra.encoder.layer.8.attention.self.query.weight', 'electra.embeddings.LayerNorm.weight', 'electra.encoder.layer.11.attention.self.key.weight', 'electra.encoder.layer.4.attention.output.dense.bias', 'electra.encoder.layer.7.attention.self.query.weight', 'electra.encoder.layer.11.attention.output.dense.weight', 'electra.encoder.layer.5.attention.self.key.bias', 'electra.encoder.layer.10.attention.self.key.bias', 'electra.encoder.layer.10.attention.self.value.bias', 'electra.encoder.layer.3.attention.self.key.weight', 'electra.encoder.layer.10.attention.output.dense.bias', 'electra.encoder.layer.7.attention.output.LayerNorm.bias', 'electra.encoder.layer.1.intermediate.dense.bias', 'electra.encoder.layer.8.attention.self.value.bias', 'electra.encoder.layer.7.attention.output.LayerNorm.weight', 'electra.encoder.layer.11.attention.self.key.bias', 'electra.encoder.layer.2.attention.output.dense.bias', 'electra.encoder.layer.4.attention.output.LayerNorm.bias', 'electra.encoder.layer.6.attention.output.dense.bias', 'electra.encoder.layer.10.attention.output.LayerNorm.weight', 'electra.encoder.layer.11.attention.output.LayerNorm.weight', 'electra.encoder.layer.8.attention.output.LayerNorm.weight', 'electra.encoder.layer.9.output.LayerNorm.weight', 'electra.encoder.layer.4.intermediate.dense.weight', 'electra.encoder.layer.8.output.dense.bias', 'electra.encoder.layer.10.output.LayerNorm.bias', 'electra.encoder.layer.7.intermediate.dense.weight', 'electra.encoder.layer.11.intermediate.dense.weight', 'electra.encoder.layer.8.intermediate.dense.weight', 'electra.encoder.layer.6.intermediate.dense.weight', 'electra.encoder.layer.6.attention.output.LayerNorm.weight', 'electra.encoder.layer.3.attention.output.LayerNorm.bias', 'electra.encoder.layer.3.output.dense.weight', 'electra.encoder.layer.0.attention.self.key.weight', 'electra.encoder.layer.1.attention.output.dense.weight', 'electra.encoder.layer.3.intermediate.dense.weight', 'electra.encoder.layer.6.output.dense.bias', 'electra.encoder.layer.2.attention.output.dense.weight', 'electra.embeddings_project.bias', 'electra.encoder.layer.1.attention.self.key.bias', 'electra.encoder.layer.5.output.LayerNorm.weight', 'electra.encoder.layer.2.attention.self.key.bias', 'electra.encoder.layer.6.attention.output.dense.weight', 'electra.encoder.layer.10.intermediate.dense.bias', 'electra.encoder.layer.8.output.LayerNorm.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at monologg/koelectra-small-v2-discriminator and are newly initialized: ['encoder.layer.9.attention.self.key.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.7.attention.self.query.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.11.attention.self.value.bias', 'pooler.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.11.attention.self.value.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.2.intermediate.dense.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.3.attention.self.key.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.6.attention.self.key.weight', 'pooler.dense.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.output.dense.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.4.intermediate.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
end loading
You are using a model of type electra to instantiate a model of type xlm-roberta. This is not supported for all configurations of models and can yield errors.
Some weights of the model checkpoint at monologg/koelectra-small-v2-discriminator were not used when initializing XLMRobertaModel: ['electra.encoder.layer.8.attention.self.key.weight', 'electra.encoder.layer.9.intermediate.dense.bias', 'electra.encoder.layer.6.output.LayerNorm.bias', 'electra.encoder.layer.1.output.dense.weight', 'electra.encoder.layer.10.attention.output.dense.weight', 'electra.embeddings.position_embeddings.weight', 'electra.encoder.layer.11.attention.self.query.bias', 'electra.encoder.layer.9.attention.self.value.weight', 'electra.encoder.layer.9.output.dense.bias', 'electra.encoder.layer.8.attention.output.dense.weight', 'electra.encoder.layer.8.output.dense.weight', 'electra.encoder.layer.1.attention.self.value.weight', 'electra.encoder.layer.11.attention.self.query.weight', 'electra.encoder.layer.10.output.LayerNorm.weight', 'electra.encoder.layer.7.output.LayerNorm.bias', 'electra.encoder.layer.8.intermediate.dense.bias', 'electra.encoder.layer.0.output.dense.bias', 'electra.encoder.layer.0.attention.output.dense.bias', 'electra.encoder.layer.2.attention.self.value.bias', 'electra.encoder.layer.4.attention.self.value.weight', 'electra.encoder.layer.6.attention.output.LayerNorm.bias', 'electra.encoder.layer.9.attention.output.LayerNorm.bias', 'electra.encoder.layer.5.attention.self.key.weight', 'electra.encoder.layer.2.attention.output.LayerNorm.bias', 'electra.encoder.layer.1.intermediate.dense.weight', 'electra.encoder.layer.6.intermediate.dense.bias', 'electra.encoder.layer.0.attention.self.query.bias', 'electra.encoder.layer.11.attention.output.LayerNorm.bias', 'electra.encoder.layer.0.attention.self.query.weight', 'electra.encoder.layer.0.attention.output.LayerNorm.weight', 'electra.encoder.layer.5.attention.self.value.weight', 'electra.encoder.layer.11.attention.self.value.weight', 'electra.embeddings.LayerNorm.bias', 'electra.encoder.layer.9.attention.output.LayerNorm.weight', 'electra.encoder.layer.10.output.dense.weight', 'electra.encoder.layer.5.intermediate.dense.bias', 'electra.encoder.layer.3.output.LayerNorm.bias', 'electra.encoder.layer.5.attention.self.value.bias', 'electra.encoder.layer.5.output.LayerNorm.bias', 'electra.encoder.layer.4.attention.output.LayerNorm.weight', 'electra.encoder.layer.0.intermediate.dense.weight', 'electra.encoder.layer.3.attention.self.value.bias', 'electra.encoder.layer.8.attention.self.value.weight', 'electra.embeddings.token_type_embeddings.weight', 'electra.encoder.layer.7.output.dense.bias', 'electra.encoder.layer.10.attention.self.query.weight', 'electra.encoder.layer.10.attention.self.query.bias', 'electra.encoder.layer.4.attention.self.query.weight', 'electra.encoder.layer.4.attention.self.query.bias', 'electra.encoder.layer.0.output.LayerNorm.bias', 'electra.encoder.layer.9.attention.output.dense.weight', 'electra.encoder.layer.2.attention.self.value.weight', 'electra.encoder.layer.5.attention.self.query.bias', 'electra.encoder.layer.10.attention.output.LayerNorm.bias', 'electra.encoder.layer.7.attention.output.dense.bias', 'electra.encoder.layer.9.intermediate.dense.weight', 'electra.encoder.layer.1.attention.self.key.weight', 'electra.encoder.layer.3.output.dense.bias', 'electra.encoder.layer.2.intermediate.dense.bias', 'electra.encoder.layer.11.attention.self.value.bias', 'electra.encoder.layer.4.intermediate.dense.bias', 'electra.encoder.layer.0.attention.self.value.weight', 'electra.encoder.layer.2.output.LayerNorm.bias', 'electra.encoder.layer.6.attention.self.value.bias', 'electra.encoder.layer.5.attention.output.dense.bias', 'electra.encoder.layer.3.output.LayerNorm.weight', 'electra.encoder.layer.10.attention.self.key.weight', 'electra.encoder.layer.10.output.dense.bias', 'electra.encoder.layer.8.attention.self.query.bias', 'electra.encoder.layer.3.attention.self.query.bias', 'electra.encoder.layer.9.attention.self.value.bias', 'electra.encoder.layer.8.attention.output.dense.bias', 'electra.encoder.layer.10.attention.self.value.weight', 'electra.encoder.layer.6.attention.self.value.weight', 'electra.encoder.layer.1.attention.output.dense.bias', 'electra.encoder.layer.5.output.dense.weight', 'electra.encoder.layer.7.output.LayerNorm.weight', 'electra.embeddings_project.weight', 'electra.encoder.layer.5.attention.output.LayerNorm.weight', 'electra.encoder.layer.0.attention.self.key.bias', 'electra.encoder.layer.6.attention.self.query.weight', 'electra.encoder.layer.1.attention.output.LayerNorm.weight', 'electra.encoder.layer.3.attention.self.key.bias', 'electra.encoder.layer.2.attention.self.query.bias', 'electra.encoder.layer.6.attention.self.key.weight', 'electra.encoder.layer.4.output.dense.bias', 'electra.encoder.layer.7.attention.self.key.weight', 'electra.encoder.layer.11.intermediate.dense.bias', 'electra.encoder.layer.9.attention.self.key.weight', 'electra.encoder.layer.1.attention.output.LayerNorm.bias', 'electra.encoder.layer.3.attention.output.dense.bias', 'electra.encoder.layer.4.attention.self.value.bias', 'electra.encoder.layer.5.output.dense.bias', 'electra.encoder.layer.1.output.LayerNorm.bias', 'electra.encoder.layer.2.output.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'electra.encoder.layer.1.output.dense.bias', 'electra.encoder.layer.2.intermediate.dense.weight', 'electra.encoder.layer.0.attention.self.value.bias', 'electra.encoder.layer.4.attention.self.key.bias', 'electra.encoder.layer.0.attention.output.LayerNorm.bias', 'electra.encoder.layer.7.attention.self.query.bias', 'electra.encoder.layer.5.attention.self.query.weight', 'electra.encoder.layer.7.attention.self.key.bias', 'electra.encoder.layer.6.output.dense.weight', 'electra.encoder.layer.8.attention.self.key.bias', 'electra.encoder.layer.4.output.LayerNorm.bias', 'electra.encoder.layer.6.output.LayerNorm.weight', 'discriminator_predictions.dense_prediction.bias', 'electra.encoder.layer.3.attention.self.query.weight', 'electra.encoder.layer.9.attention.self.key.bias', 'electra.encoder.layer.5.attention.output.LayerNorm.bias', 'electra.encoder.layer.4.output.dense.weight', 'electra.encoder.layer.7.attention.self.value.weight', 'electra.encoder.layer.11.output.dense.bias', 'electra.encoder.layer.3.attention.output.LayerNorm.weight', 'electra.encoder.layer.8.attention.output.LayerNorm.bias', 'electra.encoder.layer.8.output.LayerNorm.weight', 'electra.encoder.layer.4.output.LayerNorm.weight', 'electra.encoder.layer.9.output.dense.weight', 'electra.encoder.layer.9.attention.self.query.bias', 'electra.embeddings.word_embeddings.weight', 'electra.encoder.layer.5.attention.output.dense.weight', 'electra.encoder.layer.10.intermediate.dense.weight', 'electra.encoder.layer.4.attention.output.dense.weight', 'electra.encoder.layer.7.attention.self.value.bias', 'electra.encoder.layer.11.output.LayerNorm.weight', 'electra.encoder.layer.11.attention.output.dense.bias', 'electra.encoder.layer.0.attention.output.dense.weight', 'electra.encoder.layer.0.output.dense.weight', 'electra.encoder.layer.2.attention.self.query.weight', 'electra.encoder.layer.9.attention.output.dense.bias', 'electra.encoder.layer.4.attention.self.key.weight', 'electra.encoder.layer.6.attention.self.key.bias', 'electra.encoder.layer.1.attention.self.query.weight', 'electra.encoder.layer.2.output.LayerNorm.weight', 'electra.encoder.layer.1.output.LayerNorm.weight', 'discriminator_predictions.dense.weight', 'electra.encoder.layer.11.output.dense.weight', 'electra.encoder.layer.5.intermediate.dense.weight', 'electra.encoder.layer.7.attention.output.dense.weight', 'electra.encoder.layer.0.output.LayerNorm.weight', 'electra.encoder.layer.9.attention.self.query.weight', 'electra.encoder.layer.11.output.LayerNorm.bias', 'electra.encoder.layer.3.intermediate.dense.bias', 'discriminator_predictions.dense.bias', 'electra.encoder.layer.7.intermediate.dense.bias', 'electra.encoder.layer.2.output.dense.weight', 'electra.encoder.layer.3.attention.output.dense.weight', 'electra.encoder.layer.1.attention.self.value.bias', 'electra.encoder.layer.2.attention.output.LayerNorm.weight', 'electra.encoder.layer.2.attention.self.key.weight', 'electra.encoder.layer.9.output.LayerNorm.bias', 'electra.encoder.layer.1.attention.self.query.bias', 'electra.encoder.layer.3.attention.self.value.weight', 'electra.encoder.layer.0.intermediate.dense.bias', 'electra.encoder.layer.7.output.dense.weight', 'electra.encoder.layer.6.attention.self.query.bias', 'electra.encoder.layer.8.attention.self.query.weight', 'electra.embeddings.LayerNorm.weight', 'electra.encoder.layer.11.attention.self.key.weight', 'electra.encoder.layer.4.attention.output.dense.bias', 'electra.encoder.layer.7.attention.self.query.weight', 'electra.encoder.layer.11.attention.output.dense.weight', 'electra.encoder.layer.5.attention.self.key.bias', 'electra.encoder.layer.10.attention.self.key.bias', 'electra.encoder.layer.10.attention.self.value.bias', 'electra.encoder.layer.3.attention.self.key.weight', 'electra.encoder.layer.10.attention.output.dense.bias', 'electra.encoder.layer.7.attention.output.LayerNorm.bias', 'electra.encoder.layer.1.intermediate.dense.bias', 'electra.encoder.layer.8.attention.self.value.bias', 'electra.encoder.layer.7.attention.output.LayerNorm.weight', 'electra.encoder.layer.11.attention.self.key.bias', 'electra.encoder.layer.2.attention.output.dense.bias', 'electra.encoder.layer.4.attention.output.LayerNorm.bias', 'electra.encoder.layer.6.attention.output.dense.bias', 'electra.encoder.layer.10.attention.output.LayerNorm.weight', 'electra.encoder.layer.11.attention.output.LayerNorm.weight', 'electra.encoder.layer.8.attention.output.LayerNorm.weight', 'electra.encoder.layer.9.output.LayerNorm.weight', 'electra.encoder.layer.4.intermediate.dense.weight', 'electra.encoder.layer.8.output.dense.bias', 'electra.encoder.layer.10.output.LayerNorm.bias', 'electra.encoder.layer.7.intermediate.dense.weight', 'electra.encoder.layer.11.intermediate.dense.weight', 'electra.encoder.layer.8.intermediate.dense.weight', 'electra.encoder.layer.6.intermediate.dense.weight', 'electra.encoder.layer.6.attention.output.LayerNorm.weight', 'electra.encoder.layer.3.attention.output.LayerNorm.bias', 'electra.encoder.layer.3.output.dense.weight', 'electra.encoder.layer.0.attention.self.key.weight', 'electra.encoder.layer.1.attention.output.dense.weight', 'electra.encoder.layer.3.intermediate.dense.weight', 'electra.encoder.layer.6.output.dense.bias', 'electra.encoder.layer.2.attention.output.dense.weight', 'electra.embeddings_project.bias', 'electra.encoder.layer.1.attention.self.key.bias', 'electra.encoder.layer.5.output.LayerNorm.weight', 'electra.encoder.layer.2.attention.self.key.bias', 'electra.encoder.layer.6.attention.output.dense.weight', 'electra.encoder.layer.10.intermediate.dense.bias', 'electra.encoder.layer.8.output.LayerNorm.bias']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at monologg/koelectra-small-v2-discriminator and are newly initialized: ['encoder.layer.9.attention.self.key.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.7.attention.self.query.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.11.attention.self.value.bias', 'pooler.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.11.attention.self.value.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.2.intermediate.dense.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.3.attention.self.key.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.6.attention.self.key.weight', 'pooler.dense.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.7.output.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.output.dense.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.4.intermediate.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/nlplab/anaconda3/envs/jiwoo/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
Epoch:   0%|                                                                                                                        | 0/10 [00:00<?, ?it/s]
Entity_Property_Epoch:  1
Average train loss: 0.16866209862551648
[3002, 55672]
[0, 55672]
[0.0, 1.0]
accuracy:  0.9488359409619253
macro_accuracy:  0.3333333333333333
f1_score:  [0.         0.97374635]
f1_score_micro:  0.9488359409619253
f1_score_macro:  0.48687317440050376
Entity_polarity_Epoch:  1
Average train loss: 0.24283256717026233
[2921, 27, 54]
[2921, 0, 0]
[1.0, 0.0, 0.0]
accuracy:  0.9730179880079947
macro_accuracy:  0.3333333333333333
f1_score:  [0.9863245 0.        0.       ]
f1_score_micro:  0.9730179880079947

Epoch:  10%|██████████▌                                                                                              | 1/10 [2:23:56<21:35:29, 8636.59s/it]
Entity_Property_Epoch:  2
Average train loss: 0.15183042472660976
[3002, 55672]
[569, 55153]
[0.18954030646235842, 0.990677539876419]
accuracy:  0.9496881071684221
macro_accuracy:  0.3934059487795925
f1_score:  [0.27823961 0.97393562]
f1_score_micro:  0.9496881071684221
f1_score_macro:  0.62608761241454
Entity_polarity_Epoch:  2

Epoch:  20%|█████████████████████                                                                                    | 2/10 [4:51:04<19:26:31, 8748.97s/it]
[2921, 27, 54]
[2921, 0, 0]
[1.0, 0.0, 0.0]
accuracy:  0.9730179880079947
macro_accuracy:  0.3333333333333333
f1_score:  [0.9863245 0.        0.       ]
f1_score_micro:  0.9730179880079947
f1_score_macro:  0.32877483257358325
Entity_Property_Epoch:  3
Average train loss: 0.13664013906949327
[3002, 55672]
[1005, 55214]
[0.3347768154563624, 0.9917732432820807]
accuracy:  0.9581586392610014
macro_accuracy:  0.44218335291281435
f1_score:  [0.45016797 0.97825182]
f1_score_micro:  0.9581586392610014
f1_score_macro:  0.7142098956892994
Entity_polarity_Epoch:  3

Epoch:  30%|███████████████████████████████▌                                                                         | 3/10 [7:17:46<17:03:34, 8773.45s/it]
[2921, 27, 54]
[2921, 0, 0]
[1.0, 0.0, 0.0]
accuracy:  0.9730179880079947
macro_accuracy:  0.3333333333333333
f1_score:  [0.9863245 0.        0.       ]
f1_score_micro:  0.9730179880079947
f1_score_macro:  0.32877483257358325
Entity_Property_Epoch:  4
Average train loss: 0.12235693972771113
[3002, 55672]
[1154, 55227]
[0.3844103930712858, 0.9920067538439431]
accuracy:  0.9609196577700515
macro_accuracy:  0.4588057156384096
f1_score:  [0.50163008 0.97966243]
f1_score_micro:  0.9609196577700515
f1_score_macro:  0.7406462552298925
Entity_polarity_Epoch:  4

Epoch:  40%|██████████████████████████████████████████                                                               | 4/10 [9:39:05<14:25:41, 8656.97s/it]
[2921, 27, 54]
[2921, 0, 0]
[1.0, 0.0, 0.0]
accuracy:  0.9730179880079947
macro_accuracy:  0.3333333333333333
f1_score:  [0.9863245 0.        0.       ]
f1_score_micro:  0.9730179880079947
f1_score_macro:  0.32877483257358325
Entity_Property_Epoch:  5
Average train loss: 0.11335914155421364
[3002, 55672]
[1187, 55238]
[0.39540306462358427, 0.9922043397039805]
accuracy:  0.9616695640317687
macro_accuracy:  0.4625358014425216
f1_score:  [0.51351936 0.98004879]
f1_score_micro:  0.9616695640317687
f1_score_macro:  0.7467840755146999
Entity_polarity_Epoch:  5
Average train loss: 0.13841805270058102
[2921, 27, 54]
[2921, 0, 0]
[1.0, 0.0, 0.0]
accuracy:  0.9730179880079947
macro_accuracy:  0.3333333333333333
f1_score:  [0.98682432 0.         0.        ]
f1_score_micro:  0.9730179880079947

Epoch:  50%|████████████████████████████████████████████████████                                                    | 5/10 [12:10:27<12:14:12, 8810.52s/it]
Entity_Property_Epoch:  6
Average train loss: 0.10646712627174122
[3002, 55672]
[1199, 55250]
[0.399400399733511, 0.9924198879149303]
accuracy:  0.9620786038108873
macro_accuracy:  0.46394009588281376
f1_score:  [0.51871079 0.9802617 ]
f1_score_micro:  0.9620786038108873
f1_score_macro:  0.7494862463406881
Entity_polarity_Epoch:  6
Average train loss: 0.11743266000994482
[2921, 27, 54]
[2898, 5, 4]
[0.9921259842519685, 0.18518518518518517, 0.07407407407407407]
accuracy:  0.9683544303797469
macro_accuracy:  0.41712841450374255
f1_score:  [0.98504419 0.25641026 0.09876543]
f1_score_micro:  0.9683544303797469

Epoch:  60%|███████████████████████████████████████████████████████████████                                          | 6/10 [14:41:58<9:53:42, 8905.64s/it]
Entity_Property_Epoch:  7
Average train loss: 0.101460973755294
[3002, 55672]
[1305, 55113]
[0.4347101932045303, 0.9899590458399196]
accuracy:  0.9615502607628592
macro_accuracy:  0.4748897463481499
f1_score:  [0.53637485 0.97994346]
f1_score_micro:  0.9615502607628592
f1_score_macro:  0.7581591517445916
Entity_polarity_Epoch:  7
Average train loss: 0.0927732961717993
[2921, 27, 54]
[2870, 6, 7]
[0.9825402259500171, 0.2222222222222222, 0.12962962962962962]
accuracy:  0.9603597601598934
macro_accuracy:  0.44479735926728964
f1_score:  [0.98102888 0.26086957 0.13084112]
f1_score_micro:  0.9603597601598934

Epoch:  70%|█████████████████████████████████████████████████████████████████████████▌                               | 7/10 [17:14:06<7:28:55, 8978.38s/it]
Entity_Property_Epoch:  8
Average train loss: 0.09607620367119656
[3002, 55672]
[1275, 55133]
[0.42471685542971355, 0.9903182928581693]
accuracy:  0.9613798275215598
macro_accuracy:  0.47167838276262763
f1_score:  [0.52948505 0.97986351]
f1_score_micro:  0.9613798275215599
f1_score_macro:  0.7546742776628291
Entity_polarity_Epoch:  8
Average train loss: 0.08881811813625973
[2921, 27, 54]
[2895, 5, 6]
[0.9910989387196165, 0.18518518518518517, 0.1111111111111111]
accuracy:  0.9680213191205863
macro_accuracy:  0.42913174500530427
f1_score:  [0.98469388 0.25       0.14285714]
f1_score_micro:  0.9680213191205863

Epoch:  80%|████████████████████████████████████████████████████████████████████████████████████                     | 8/10 [19:46:26<5:00:59, 9029.88s/it]
Entity_Property_Epoch:  9
Average train loss: 0.09122640685928686
[3002, 55672]
[1426, 54961]
[0.475016655562958, 0.9872287685012214]
accuracy:  0.9610219177148311
macro_accuracy:  0.4874151413547265
f1_score:  [0.55497178 0.97961839]
f1_score_micro:  0.9610219177148311
f1_score_macro:  0.7672950875377627
Entity_polarity_Epoch:  9
Average train loss: 0.07714247950352729
[2921, 27, 54]
[2896, 5, 6]
[0.9914412872304006, 0.18518518518518517, 0.1111111111111111]
accuracy:  0.9683544303797469
macro_accuracy:  0.4292458611755656
f1_score:  [0.98486652 0.26315789 0.14117647]
f1_score_micro:  0.9683544303797469

Epoch:  90%|██████████████████████████████████████████████████████████████████████████████████████████████▌          | 9/10 [22:18:30<2:30:59, 9059.43s/it]
Entity_Property_Epoch:  10
Average train loss: 0.08808981340482971
[3002, 55672]
[1350, 55090]
[0.4497001998667555, 0.9895459117689324]
accuracy:  0.9619252138937179
macro_accuracy:  0.4797487038785626
f1_score:  [0.54722335 0.98012703]
f1_score_micro:  0.9619252138937179
f1_score_macro:  0.7636751893186191
Entity_polarity_Epoch:  10
Average train loss: 0.07374934054678306
[2921, 27, 54]
[2902, 5, 6]
[0.9934953782951044, 0.18518518518518517, 0.1111111111111111]
accuracy:  0.9703530979347101
macro_accuracy:  0.42993055819713355
f1_score:  [0.98556631 0.27777778 0.15189873]
f1_score_micro:  0.9703530979347101
f1_score_macro:  0.4717476073415381

Epoch: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [24:44:35<00:00, 8907.57s/it]