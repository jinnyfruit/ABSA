training_phase start . . .
train_sentiment_analysis
entity property model would be saved at  ./saved_models/default_path/
polarity model would be saved at  ./saved_models/default_path/
loading train data
tokenizing train data
We have added 8 tokens
polarity_data_count:  3194
entity_property_data_count:  59827
polarity_data_count:  6196
entity_property_data_count:  115499
loading model
You are using a model of type electra to instantiate a model of type xlm-roberta. This is not supported for all configurations of models and can yield errors.
Some weights of the model checkpoint at monologg/koelectra-small-v2-discriminator were not used when initializing XLMRobertaModel: ['electra.encoder.layer.5.attention.self.query.weight', 'electra.embeddings.LayerNorm.weight', 'electra.encoder.layer.3.output.dense.weight', 'electra.encoder.layer.9.intermediate.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'electra.encoder.layer.7.output.LayerNorm.bias', 'electra.encoder.layer.3.attention.output.dense.bias', 'electra.encoder.layer.6.attention.self.query.bias', 'electra.encoder.layer.1.output.dense.weight', 'electra.encoder.layer.9.output.LayerNorm.bias', 'electra.encoder.layer.10.attention.self.key.weight', 'electra.encoder.layer.10.attention.self.value.bias', 'electra.encoder.layer.6.intermediate.dense.bias', 'electra.encoder.layer.7.attention.output.LayerNorm.weight', 'electra.encoder.layer.3.attention.self.query.bias', 'electra.encoder.layer.2.output.dense.bias', 'electra.encoder.layer.2.intermediate.dense.bias', 'electra.encoder.layer.6.attention.self.value.bias', 'electra.encoder.layer.9.attention.output.dense.bias', 'electra.encoder.layer.0.attention.self.key.weight', 'electra.encoder.layer.5.output.LayerNorm.weight', 'electra.encoder.layer.5.attention.output.dense.weight', 'electra.encoder.layer.7.attention.self.value.bias', 'electra.encoder.layer.8.intermediate.dense.weight', 'electra.encoder.layer.1.attention.self.query.weight', 'electra.encoder.layer.2.output.dense.weight', 'electra.encoder.layer.9.attention.self.key.weight', 'electra.encoder.layer.10.attention.output.LayerNorm.weight', 'electra.encoder.layer.10.output.LayerNorm.weight', 'electra.encoder.layer.5.output.dense.weight', 'electra.encoder.layer.9.intermediate.dense.weight', 'electra.encoder.layer.3.attention.self.value.bias', 'electra.encoder.layer.6.attention.output.LayerNorm.bias', 'electra.encoder.layer.9.output.dense.weight', 'electra.encoder.layer.1.attention.self.key.weight', 'electra.encoder.layer.5.output.dense.bias', 'electra.encoder.layer.2.intermediate.dense.weight', 'electra.encoder.layer.6.attention.output.dense.bias', 'electra.encoder.layer.1.attention.self.value.weight', 'electra.encoder.layer.0.attention.self.key.bias', 'electra.encoder.layer.2.attention.self.query.weight', 'electra.encoder.layer.0.output.dense.weight', 'electra.encoder.layer.6.attention.output.LayerNorm.weight', 'electra.encoder.layer.8.attention.output.dense.weight', 'electra.embeddings.token_type_embeddings.weight', 'electra.encoder.layer.7.attention.self.key.bias', 'electra.encoder.layer.3.attention.self.key.weight', 'electra.encoder.layer.3.attention.self.query.weight', 'electra.encoder.layer.10.output.LayerNorm.bias', 'electra.encoder.layer.5.attention.self.key.weight', 'electra.encoder.layer.7.attention.output.dense.weight', 'electra.encoder.layer.2.attention.output.dense.weight', 'electra.encoder.layer.4.attention.output.LayerNorm.weight', 'electra.encoder.layer.4.attention.self.value.bias', 'electra.encoder.layer.0.output.LayerNorm.bias', 'electra.encoder.layer.1.intermediate.dense.bias', 'electra.encoder.layer.0.intermediate.dense.weight', 'electra.encoder.layer.5.intermediate.dense.bias', 'electra.encoder.layer.9.attention.self.value.weight', 'electra.encoder.layer.9.attention.self.key.bias', 'electra.encoder.layer.7.output.dense.bias', 'electra.encoder.layer.9.attention.self.value.bias', 'electra.encoder.layer.0.attention.self.value.bias', 'electra.encoder.layer.2.attention.output.LayerNorm.bias', 'electra.encoder.layer.8.output.LayerNorm.weight', 'electra.encoder.layer.7.output.LayerNorm.weight', 'electra.encoder.layer.3.attention.self.key.bias', 'electra.embeddings_project.bias', 'electra.encoder.layer.1.attention.self.query.bias', 'electra.encoder.layer.4.attention.output.dense.bias', 'electra.encoder.layer.10.output.dense.bias', 'electra.encoder.layer.2.attention.output.LayerNorm.weight', 'electra.encoder.layer.5.attention.self.query.bias', 'electra.encoder.layer.11.attention.output.dense.weight', 'electra.encoder.layer.10.intermediate.dense.bias', 'electra.encoder.layer.1.output.LayerNorm.weight', 'discriminator_predictions.dense.bias', 'electra.encoder.layer.0.attention.self.query.bias', 'electra.encoder.layer.5.attention.output.dense.bias', 'electra.encoder.layer.2.output.LayerNorm.weight', 'electra.encoder.layer.4.output.LayerNorm.weight', 'electra.encoder.layer.9.attention.output.dense.weight', 'electra.encoder.layer.4.attention.output.LayerNorm.bias', 'electra.encoder.layer.8.attention.output.dense.bias', 'electra.encoder.layer.1.intermediate.dense.weight', 'electra.encoder.layer.8.attention.self.query.weight', 'electra.encoder.layer.0.attention.output.LayerNorm.bias', 'electra.encoder.layer.10.attention.self.query.weight', 'electra.encoder.layer.2.attention.self.key.bias', 'electra.encoder.layer.4.output.dense.weight', 'electra.encoder.layer.6.output.LayerNorm.weight', 'electra.encoder.layer.2.attention.self.value.weight', 'electra.encoder.layer.8.attention.self.key.bias', 'electra.encoder.layer.1.output.LayerNorm.bias', 'electra.encoder.layer.8.intermediate.dense.bias', 'electra.encoder.layer.3.output.LayerNorm.weight', 'electra.encoder.layer.9.attention.self.query.weight', 'electra.encoder.layer.5.intermediate.dense.weight', 'electra.encoder.layer.7.attention.self.key.weight', 'electra.encoder.layer.10.attention.self.value.weight', 'electra.encoder.layer.10.attention.self.query.bias', 'electra.encoder.layer.4.attention.self.query.weight', 'electra.encoder.layer.3.attention.output.dense.weight', 'discriminator_predictions.dense_prediction.bias', 'electra.encoder.layer.11.output.LayerNorm.bias', 'electra.encoder.layer.6.attention.self.value.weight', 'electra.encoder.layer.0.attention.self.query.weight', 'electra.encoder.layer.11.output.dense.bias', 'electra.encoder.layer.3.output.LayerNorm.bias', 'electra.encoder.layer.10.intermediate.dense.weight', 'electra.encoder.layer.8.output.dense.bias', 'electra.encoder.layer.8.attention.self.value.weight', 'electra.encoder.layer.11.output.dense.weight', 'electra.encoder.layer.7.intermediate.dense.weight', 'electra.encoder.layer.11.attention.self.query.weight', 'electra.encoder.layer.11.attention.output.LayerNorm.bias', 'electra.encoder.layer.6.attention.self.key.weight', 'electra.encoder.layer.4.attention.self.key.bias', 'electra.encoder.layer.9.output.dense.bias', 'electra.encoder.layer.4.attention.self.value.weight', 'electra.encoder.layer.3.attention.output.LayerNorm.weight', 'electra.encoder.layer.1.attention.self.key.bias', 'electra.encoder.layer.7.attention.output.dense.bias', 'electra.encoder.layer.0.output.LayerNorm.weight', 'electra.encoder.layer.11.attention.self.value.weight', 'electra.encoder.layer.11.attention.self.key.weight', 'electra.encoder.layer.0.attention.output.dense.bias', 'electra.encoder.layer.8.attention.output.LayerNorm.bias', 'electra.encoder.layer.11.attention.self.key.bias', 'electra.encoder.layer.1.attention.output.LayerNorm.bias', 'electra.encoder.layer.10.attention.output.dense.bias', 'electra.encoder.layer.1.attention.output.LayerNorm.weight', 'electra.encoder.layer.11.intermediate.dense.weight', 'electra.encoder.layer.3.attention.output.LayerNorm.bias', 'electra.encoder.layer.10.attention.output.dense.weight', 'electra.encoder.layer.1.output.dense.bias', 'electra.encoder.layer.6.output.dense.weight', 'electra.encoder.layer.9.attention.output.LayerNorm.weight', 'electra.encoder.layer.3.output.dense.bias', 'electra.encoder.layer.2.attention.self.key.weight', 'electra.encoder.layer.5.attention.self.value.bias', 'electra.encoder.layer.2.attention.self.value.bias', 'electra.encoder.layer.2.attention.output.dense.bias', 'electra.encoder.layer.6.attention.self.key.bias', 'electra.encoder.layer.8.attention.self.query.bias', 'electra.encoder.layer.9.output.LayerNorm.weight', 'electra.encoder.layer.9.attention.self.query.bias', 'electra.encoder.layer.1.attention.self.value.bias', 'electra.encoder.layer.4.intermediate.dense.bias', 'electra.encoder.layer.3.intermediate.dense.bias', 'electra.encoder.layer.2.attention.self.query.bias', 'electra.encoder.layer.5.attention.self.key.bias', 'electra.embeddings_project.weight', 'electra.encoder.layer.6.attention.self.query.weight', 'electra.encoder.layer.6.output.dense.bias', 'electra.encoder.layer.6.output.LayerNorm.bias', 'electra.encoder.layer.7.intermediate.dense.bias', 'electra.encoder.layer.0.attention.self.value.weight', 'electra.encoder.layer.7.attention.output.LayerNorm.bias', 'electra.encoder.layer.7.output.dense.weight', 'electra.encoder.layer.10.attention.self.key.bias', 'electra.encoder.layer.0.output.dense.bias', 'electra.encoder.layer.4.attention.self.key.weight', 'electra.encoder.layer.4.attention.output.dense.weight', 'electra.embeddings.LayerNorm.bias', 'electra.encoder.layer.8.attention.output.LayerNorm.weight', 'electra.encoder.layer.6.attention.output.dense.weight', 'electra.encoder.layer.7.attention.self.query.bias', 'electra.encoder.layer.11.attention.self.value.bias', 'electra.encoder.layer.3.intermediate.dense.weight', 'electra.encoder.layer.4.intermediate.dense.weight', 'electra.embeddings.position_embeddings.weight', 'electra.encoder.layer.5.attention.output.LayerNorm.weight', 'electra.encoder.layer.8.attention.self.value.bias', 'electra.encoder.layer.0.intermediate.dense.bias', 'electra.encoder.layer.4.attention.self.query.bias', 'electra.encoder.layer.2.output.LayerNorm.bias', 'electra.encoder.layer.8.output.LayerNorm.bias', 'electra.encoder.layer.11.attention.self.query.bias', 'electra.encoder.layer.4.output.LayerNorm.bias', 'electra.encoder.layer.11.attention.output.dense.bias', 'electra.encoder.layer.3.attention.self.value.weight', 'electra.encoder.layer.7.attention.self.query.weight', 'electra.encoder.layer.1.attention.output.dense.weight', 'electra.encoder.layer.5.attention.output.LayerNorm.bias', 'electra.encoder.layer.8.attention.self.key.weight', 'electra.embeddings.word_embeddings.weight', 'electra.encoder.layer.8.output.dense.weight', 'electra.encoder.layer.5.attention.self.value.weight', 'electra.encoder.layer.0.attention.output.LayerNorm.weight', 'electra.encoder.layer.1.attention.output.dense.bias', 'electra.encoder.layer.4.output.dense.bias', 'electra.encoder.layer.7.attention.self.value.weight', 'electra.encoder.layer.6.intermediate.dense.weight', 'discriminator_predictions.dense.weight', 'electra.encoder.layer.5.output.LayerNorm.bias', 'electra.encoder.layer.0.attention.output.dense.weight', 'electra.encoder.layer.11.attention.output.LayerNorm.weight', 'electra.encoder.layer.11.output.LayerNorm.weight', 'electra.encoder.layer.11.intermediate.dense.bias', 'electra.encoder.layer.9.attention.output.LayerNorm.bias', 'electra.encoder.layer.10.attention.output.LayerNorm.bias', 'electra.encoder.layer.10.output.dense.weight']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at monologg/koelectra-small-v2-discriminator and are newly initialized: ['encoder.layer.10.attention.output.dense.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'pooler.dense.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.8.attention.self.value.bias', 'embeddings.LayerNorm.bias', 'pooler.dense.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.9.attention.self.value.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.6.output.dense.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.7.intermediate.dense.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.key.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.attention.self.key.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
end loading
You are using a model of type electra to instantiate a model of type xlm-roberta. This is not supported for all configurations of models and can yield errors.
Some weights of the model checkpoint at monologg/koelectra-small-v2-discriminator were not used when initializing XLMRobertaModel: ['electra.encoder.layer.5.attention.self.query.weight', 'electra.embeddings.LayerNorm.weight', 'electra.encoder.layer.3.output.dense.weight', 'electra.encoder.layer.9.intermediate.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'electra.encoder.layer.7.output.LayerNorm.bias', 'electra.encoder.layer.3.attention.output.dense.bias', 'electra.encoder.layer.6.attention.self.query.bias', 'electra.encoder.layer.1.output.dense.weight', 'electra.encoder.layer.9.output.LayerNorm.bias', 'electra.encoder.layer.10.attention.self.key.weight', 'electra.encoder.layer.10.attention.self.value.bias', 'electra.encoder.layer.6.intermediate.dense.bias', 'electra.encoder.layer.7.attention.output.LayerNorm.weight', 'electra.encoder.layer.3.attention.self.query.bias', 'electra.encoder.layer.2.output.dense.bias', 'electra.encoder.layer.2.intermediate.dense.bias', 'electra.encoder.layer.6.attention.self.value.bias', 'electra.encoder.layer.9.attention.output.dense.bias', 'electra.encoder.layer.0.attention.self.key.weight', 'electra.encoder.layer.5.output.LayerNorm.weight', 'electra.encoder.layer.5.attention.output.dense.weight', 'electra.encoder.layer.7.attention.self.value.bias', 'electra.encoder.layer.8.intermediate.dense.weight', 'electra.encoder.layer.1.attention.self.query.weight', 'electra.encoder.layer.2.output.dense.weight', 'electra.encoder.layer.9.attention.self.key.weight', 'electra.encoder.layer.10.attention.output.LayerNorm.weight', 'electra.encoder.layer.10.output.LayerNorm.weight', 'electra.encoder.layer.5.output.dense.weight', 'electra.encoder.layer.9.intermediate.dense.weight', 'electra.encoder.layer.3.attention.self.value.bias', 'electra.encoder.layer.6.attention.output.LayerNorm.bias', 'electra.encoder.layer.9.output.dense.weight', 'electra.encoder.layer.1.attention.self.key.weight', 'electra.encoder.layer.5.output.dense.bias', 'electra.encoder.layer.2.intermediate.dense.weight', 'electra.encoder.layer.6.attention.output.dense.bias', 'electra.encoder.layer.1.attention.self.value.weight', 'electra.encoder.layer.0.attention.self.key.bias', 'electra.encoder.layer.2.attention.self.query.weight', 'electra.encoder.layer.0.output.dense.weight', 'electra.encoder.layer.6.attention.output.LayerNorm.weight', 'electra.encoder.layer.8.attention.output.dense.weight', 'electra.embeddings.token_type_embeddings.weight', 'electra.encoder.layer.7.attention.self.key.bias', 'electra.encoder.layer.3.attention.self.key.weight', 'electra.encoder.layer.3.attention.self.query.weight', 'electra.encoder.layer.10.output.LayerNorm.bias', 'electra.encoder.layer.5.attention.self.key.weight', 'electra.encoder.layer.7.attention.output.dense.weight', 'electra.encoder.layer.2.attention.output.dense.weight', 'electra.encoder.layer.4.attention.output.LayerNorm.weight', 'electra.encoder.layer.4.attention.self.value.bias', 'electra.encoder.layer.0.output.LayerNorm.bias', 'electra.encoder.layer.1.intermediate.dense.bias', 'electra.encoder.layer.0.intermediate.dense.weight', 'electra.encoder.layer.5.intermediate.dense.bias', 'electra.encoder.layer.9.attention.self.value.weight', 'electra.encoder.layer.9.attention.self.key.bias', 'electra.encoder.layer.7.output.dense.bias', 'electra.encoder.layer.9.attention.self.value.bias', 'electra.encoder.layer.0.attention.self.value.bias', 'electra.encoder.layer.2.attention.output.LayerNorm.bias', 'electra.encoder.layer.8.output.LayerNorm.weight', 'electra.encoder.layer.7.output.LayerNorm.weight', 'electra.encoder.layer.3.attention.self.key.bias', 'electra.embeddings_project.bias', 'electra.encoder.layer.1.attention.self.query.bias', 'electra.encoder.layer.4.attention.output.dense.bias', 'electra.encoder.layer.10.output.dense.bias', 'electra.encoder.layer.2.attention.output.LayerNorm.weight', 'electra.encoder.layer.5.attention.self.query.bias', 'electra.encoder.layer.11.attention.output.dense.weight', 'electra.encoder.layer.10.intermediate.dense.bias', 'electra.encoder.layer.1.output.LayerNorm.weight', 'discriminator_predictions.dense.bias', 'electra.encoder.layer.0.attention.self.query.bias', 'electra.encoder.layer.5.attention.output.dense.bias', 'electra.encoder.layer.2.output.LayerNorm.weight', 'electra.encoder.layer.4.output.LayerNorm.weight', 'electra.encoder.layer.9.attention.output.dense.weight', 'electra.encoder.layer.4.attention.output.LayerNorm.bias', 'electra.encoder.layer.8.attention.output.dense.bias', 'electra.encoder.layer.1.intermediate.dense.weight', 'electra.encoder.layer.8.attention.self.query.weight', 'electra.encoder.layer.0.attention.output.LayerNorm.bias', 'electra.encoder.layer.10.attention.self.query.weight', 'electra.encoder.layer.2.attention.self.key.bias', 'electra.encoder.layer.4.output.dense.weight', 'electra.encoder.layer.6.output.LayerNorm.weight', 'electra.encoder.layer.2.attention.self.value.weight', 'electra.encoder.layer.8.attention.self.key.bias', 'electra.encoder.layer.1.output.LayerNorm.bias', 'electra.encoder.layer.8.intermediate.dense.bias', 'electra.encoder.layer.3.output.LayerNorm.weight', 'electra.encoder.layer.9.attention.self.query.weight', 'electra.encoder.layer.5.intermediate.dense.weight', 'electra.encoder.layer.7.attention.self.key.weight', 'electra.encoder.layer.10.attention.self.value.weight', 'electra.encoder.layer.10.attention.self.query.bias', 'electra.encoder.layer.4.attention.self.query.weight', 'electra.encoder.layer.3.attention.output.dense.weight', 'discriminator_predictions.dense_prediction.bias', 'electra.encoder.layer.11.output.LayerNorm.bias', 'electra.encoder.layer.6.attention.self.value.weight', 'electra.encoder.layer.0.attention.self.query.weight', 'electra.encoder.layer.11.output.dense.bias', 'electra.encoder.layer.3.output.LayerNorm.bias', 'electra.encoder.layer.10.intermediate.dense.weight', 'electra.encoder.layer.8.output.dense.bias', 'electra.encoder.layer.8.attention.self.value.weight', 'electra.encoder.layer.11.output.dense.weight', 'electra.encoder.layer.7.intermediate.dense.weight', 'electra.encoder.layer.11.attention.self.query.weight', 'electra.encoder.layer.11.attention.output.LayerNorm.bias', 'electra.encoder.layer.6.attention.self.key.weight', 'electra.encoder.layer.4.attention.self.key.bias', 'electra.encoder.layer.9.output.dense.bias', 'electra.encoder.layer.4.attention.self.value.weight', 'electra.encoder.layer.3.attention.output.LayerNorm.weight', 'electra.encoder.layer.1.attention.self.key.bias', 'electra.encoder.layer.7.attention.output.dense.bias', 'electra.encoder.layer.0.output.LayerNorm.weight', 'electra.encoder.layer.11.attention.self.value.weight', 'electra.encoder.layer.11.attention.self.key.weight', 'electra.encoder.layer.0.attention.output.dense.bias', 'electra.encoder.layer.8.attention.output.LayerNorm.bias', 'electra.encoder.layer.11.attention.self.key.bias', 'electra.encoder.layer.1.attention.output.LayerNorm.bias', 'electra.encoder.layer.10.attention.output.dense.bias', 'electra.encoder.layer.1.attention.output.LayerNorm.weight', 'electra.encoder.layer.11.intermediate.dense.weight', 'electra.encoder.layer.3.attention.output.LayerNorm.bias', 'electra.encoder.layer.10.attention.output.dense.weight', 'electra.encoder.layer.1.output.dense.bias', 'electra.encoder.layer.6.output.dense.weight', 'electra.encoder.layer.9.attention.output.LayerNorm.weight', 'electra.encoder.layer.3.output.dense.bias', 'electra.encoder.layer.2.attention.self.key.weight', 'electra.encoder.layer.5.attention.self.value.bias', 'electra.encoder.layer.2.attention.self.value.bias', 'electra.encoder.layer.2.attention.output.dense.bias', 'electra.encoder.layer.6.attention.self.key.bias', 'electra.encoder.layer.8.attention.self.query.bias', 'electra.encoder.layer.9.output.LayerNorm.weight', 'electra.encoder.layer.9.attention.self.query.bias', 'electra.encoder.layer.1.attention.self.value.bias', 'electra.encoder.layer.4.intermediate.dense.bias', 'electra.encoder.layer.3.intermediate.dense.bias', 'electra.encoder.layer.2.attention.self.query.bias', 'electra.encoder.layer.5.attention.self.key.bias', 'electra.embeddings_project.weight', 'electra.encoder.layer.6.attention.self.query.weight', 'electra.encoder.layer.6.output.dense.bias', 'electra.encoder.layer.6.output.LayerNorm.bias', 'electra.encoder.layer.7.intermediate.dense.bias', 'electra.encoder.layer.0.attention.self.value.weight', 'electra.encoder.layer.7.attention.output.LayerNorm.bias', 'electra.encoder.layer.7.output.dense.weight', 'electra.encoder.layer.10.attention.self.key.bias', 'electra.encoder.layer.0.output.dense.bias', 'electra.encoder.layer.4.attention.self.key.weight', 'electra.encoder.layer.4.attention.output.dense.weight', 'electra.embeddings.LayerNorm.bias', 'electra.encoder.layer.8.attention.output.LayerNorm.weight', 'electra.encoder.layer.6.attention.output.dense.weight', 'electra.encoder.layer.7.attention.self.query.bias', 'electra.encoder.layer.11.attention.self.value.bias', 'electra.encoder.layer.3.intermediate.dense.weight', 'electra.encoder.layer.4.intermediate.dense.weight', 'electra.embeddings.position_embeddings.weight', 'electra.encoder.layer.5.attention.output.LayerNorm.weight', 'electra.encoder.layer.8.attention.self.value.bias', 'electra.encoder.layer.0.intermediate.dense.bias', 'electra.encoder.layer.4.attention.self.query.bias', 'electra.encoder.layer.2.output.LayerNorm.bias', 'electra.encoder.layer.8.output.LayerNorm.bias', 'electra.encoder.layer.11.attention.self.query.bias', 'electra.encoder.layer.4.output.LayerNorm.bias', 'electra.encoder.layer.11.attention.output.dense.bias', 'electra.encoder.layer.3.attention.self.value.weight', 'electra.encoder.layer.7.attention.self.query.weight', 'electra.encoder.layer.1.attention.output.dense.weight', 'electra.encoder.layer.5.attention.output.LayerNorm.bias', 'electra.encoder.layer.8.attention.self.key.weight', 'electra.embeddings.word_embeddings.weight', 'electra.encoder.layer.8.output.dense.weight', 'electra.encoder.layer.5.attention.self.value.weight', 'electra.encoder.layer.0.attention.output.LayerNorm.weight', 'electra.encoder.layer.1.attention.output.dense.bias', 'electra.encoder.layer.4.output.dense.bias', 'electra.encoder.layer.7.attention.self.value.weight', 'electra.encoder.layer.6.intermediate.dense.weight', 'discriminator_predictions.dense.weight', 'electra.encoder.layer.5.output.LayerNorm.bias', 'electra.encoder.layer.0.attention.output.dense.weight', 'electra.encoder.layer.11.attention.output.LayerNorm.weight', 'electra.encoder.layer.11.output.LayerNorm.weight', 'electra.encoder.layer.11.intermediate.dense.bias', 'electra.encoder.layer.9.attention.output.LayerNorm.bias', 'electra.encoder.layer.10.attention.output.LayerNorm.bias', 'electra.encoder.layer.10.output.dense.weight']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at monologg/koelectra-small-v2-discriminator and are newly initialized: ['encoder.layer.10.attention.output.dense.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'pooler.dense.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.8.attention.self.value.bias', 'embeddings.LayerNorm.bias', 'pooler.dense.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.9.attention.self.value.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.6.output.dense.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.7.intermediate.dense.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.key.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.attention.self.key.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/home/nlplab/anaconda3/envs/jiwoo/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
Epoch:   0%|                                                                                                                                                 | 0/5 [00:00<?, ?it/s]
Entity_Property_Epoch:  1
Average train loss: 0.17910358613785135
[3002, 55672]
[53, 55643]
[0.01765489673550966, 0.9994790918235379]
accuracy:  0.9492449807410437
macro_accuracy:  0.3390446628530159
f1_score:  [0.03437095 0.97393755]
f1_score_micro:  0.9492449807410437
f1_score_macro:  0.5041542474782271
Entity_polarity_Epoch:  1

Epoch:  20%|██████████████████████████▏                                                                                                        | 1/5 [1:46:15<7:05:00, 6375.24s/it]
[2921, 27, 54]
[2921, 0, 0]
[1.0, 0.0, 0.0]
accuracy:  0.9730179880079947
macro_accuracy:  0.3333333333333333
f1_score:  [0.9863245 0.        0.       ]
f1_score_micro:  0.9730179880079947
f1_score_macro:  0.32877483257358325
Entity_Property_Epoch:  2
Average train loss: 0.16089216888300942
[3002, 55672]
[160, 55639]
[0.05329780146568954, 0.9994072424198879]
accuracy:  0.9510004431264274
macro_accuracy:  0.35090168129519245
f1_score:  [0.10015649 0.9748145 ]
f1_score_micro:  0.9510004431264274
f1_score_macro:  0.5374854989323488
Entity_polarity_Epoch:  2

Epoch:  40%|████████████████████████████████████████████████████▍                                                                              | 2/5 [3:32:22<5:18:31, 6370.53s/it]
[2921, 27, 54]
[2921, 0, 0]
[1.0, 0.0, 0.0]
accuracy:  0.9730179880079947
macro_accuracy:  0.3333333333333333
f1_score:  [0.9863245 0.        0.       ]
f1_score_micro:  0.9730179880079947
f1_score_macro:  0.32877483257358325
Entity_Property_Epoch:  3
Average train loss: 0.15050642746543821
[3002, 55672]
[1165, 55084]
[0.388074616922052, 0.9894381376634573]
accuracy:  0.9586699389848996
macro_accuracy:  0.45917091819516975
f1_score:  [0.49001052 0.97846225]
f1_score_micro:  0.9586699389848996
f1_score_macro:  0.7342363821161957
Entity_polarity_Epoch:  3
Average train loss: 0.22515961088240147
[2921, 27, 54]
[2921, 0, 0]
[1.0, 0.0, 0.0]
accuracy:  0.9730179880079947
macro_accuracy:  0.3333333333333333
f1_score:  [0.9863245 0.        0.       ]
f1_score_micro:  0.9730179880079947

Epoch:  60%|██████████████████████████████████████████████████████████████████████████████▌                                                    | 3/5 [5:18:44<3:32:31, 6375.58s/it]
Entity_Property_Epoch:  4
Average train loss: 0.1407643739853667
[3002, 55672]
[1120, 55195]
[0.37308461025982675, 0.9914319586147435]
accuracy:  0.9597947983774755
macro_accuracy:  0.4548388562915234
f1_score:  [0.4870624  0.97907742]
f1_score_micro:  0.9597947983774755
f1_score_macro:  0.733069912313005
Entity_polarity_Epoch:  4

Epoch:  80%|████████████████████████████████████████████████████████████████████████████████████████████████████████▊                          | 4/5 [7:05:01<1:46:16, 6376.34s/it]
[2921, 27, 54]
[2914, 3, 0]
[0.9976035604245121, 0.1111111111111111, 0.0]
accuracy:  0.9716855429713525
macro_accuracy:  0.3695715571785411
f1_score:  [0.98595838 0.15384615 0.        ]
f1_score_micro:  0.9716855429713525
f1_score_macro:  0.3799348455075066
Entity_Property_Epoch:  5
Average train loss: 0.1349728867373429
[3002, 55672]
[1163, 55185]
[0.38740839440373087, 0.9912523351056186]
accuracy:  0.9603572280737636
macro_accuracy:  0.45955357650311646
f1_score:  [0.5       0.9793604]
f1_score_micro:  0.9603572280737636
f1_score_macro:  0.739680201604316
Entity_polarity_Epoch:  5

Epoch: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [8:51:07<00:00, 6373.59s/it]
[2921, 27, 54]
[2902, 9, 0]
[0.9934953782951044, 0.3333333333333333, 0.0]
accuracy:  0.9696868754163891
macro_accuracy:  0.44227623720947923
f1_score:  [0.98590114 0.28571429 0.        ]
f1_score_micro:  0.969686875416389
f1_score_macro:  0.42387180793839535
training is done
test_phase start . . .
polarity_data_count:  9198
entity_property_data_count:  171171
You are using a model of type electra to instantiate a model of type xlm-roberta. This is not supported for all configurations of models and can yield errors.
Some weights of the model checkpoint at monologg/koelectra-small-v2-discriminator were not used when initializing XLMRobertaModel: ['electra.encoder.layer.5.attention.self.query.weight', 'electra.embeddings.LayerNorm.weight', 'electra.encoder.layer.3.output.dense.weight', 'electra.encoder.layer.9.intermediate.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'electra.encoder.layer.7.output.LayerNorm.bias', 'electra.encoder.layer.3.attention.output.dense.bias', 'electra.encoder.layer.6.attention.self.query.bias', 'electra.encoder.layer.1.output.dense.weight', 'electra.encoder.layer.9.output.LayerNorm.bias', 'electra.encoder.layer.10.attention.self.key.weight', 'electra.encoder.layer.10.attention.self.value.bias', 'electra.encoder.layer.6.intermediate.dense.bias', 'electra.encoder.layer.7.attention.output.LayerNorm.weight', 'electra.encoder.layer.3.attention.self.query.bias', 'electra.encoder.layer.2.output.dense.bias', 'electra.encoder.layer.2.intermediate.dense.bias', 'electra.encoder.layer.6.attention.self.value.bias', 'electra.encoder.layer.9.attention.output.dense.bias', 'electra.encoder.layer.0.attention.self.key.weight', 'electra.encoder.layer.5.output.LayerNorm.weight', 'electra.encoder.layer.5.attention.output.dense.weight', 'electra.encoder.layer.7.attention.self.value.bias', 'electra.encoder.layer.8.intermediate.dense.weight', 'electra.encoder.layer.1.attention.self.query.weight', 'electra.encoder.layer.2.output.dense.weight', 'electra.encoder.layer.9.attention.self.key.weight', 'electra.encoder.layer.10.attention.output.LayerNorm.weight', 'electra.encoder.layer.10.output.LayerNorm.weight', 'electra.encoder.layer.5.output.dense.weight', 'electra.encoder.layer.9.intermediate.dense.weight', 'electra.encoder.layer.3.attention.self.value.bias', 'electra.encoder.layer.6.attention.output.LayerNorm.bias', 'electra.encoder.layer.9.output.dense.weight', 'electra.encoder.layer.1.attention.self.key.weight', 'electra.encoder.layer.5.output.dense.bias', 'electra.encoder.layer.2.intermediate.dense.weight', 'electra.encoder.layer.6.attention.output.dense.bias', 'electra.encoder.layer.1.attention.self.value.weight', 'electra.encoder.layer.0.attention.self.key.bias', 'electra.encoder.layer.2.attention.self.query.weight', 'electra.encoder.layer.0.output.dense.weight', 'electra.encoder.layer.6.attention.output.LayerNorm.weight', 'electra.encoder.layer.8.attention.output.dense.weight', 'electra.embeddings.token_type_embeddings.weight', 'electra.encoder.layer.7.attention.self.key.bias', 'electra.encoder.layer.3.attention.self.key.weight', 'electra.encoder.layer.3.attention.self.query.weight', 'electra.encoder.layer.10.output.LayerNorm.bias', 'electra.encoder.layer.5.attention.self.key.weight', 'electra.encoder.layer.7.attention.output.dense.weight', 'electra.encoder.layer.2.attention.output.dense.weight', 'electra.encoder.layer.4.attention.output.LayerNorm.weight', 'electra.encoder.layer.4.attention.self.value.bias', 'electra.encoder.layer.0.output.LayerNorm.bias', 'electra.encoder.layer.1.intermediate.dense.bias', 'electra.encoder.layer.0.intermediate.dense.weight', 'electra.encoder.layer.5.intermediate.dense.bias', 'electra.encoder.layer.9.attention.self.value.weight', 'electra.encoder.layer.9.attention.self.key.bias', 'electra.encoder.layer.7.output.dense.bias', 'electra.encoder.layer.9.attention.self.value.bias', 'electra.encoder.layer.0.attention.self.value.bias', 'electra.encoder.layer.2.attention.output.LayerNorm.bias', 'electra.encoder.layer.8.output.LayerNorm.weight', 'electra.encoder.layer.7.output.LayerNorm.weight', 'electra.encoder.layer.3.attention.self.key.bias', 'electra.embeddings_project.bias', 'electra.encoder.layer.1.attention.self.query.bias', 'electra.encoder.layer.4.attention.output.dense.bias', 'electra.encoder.layer.10.output.dense.bias', 'electra.encoder.layer.2.attention.output.LayerNorm.weight', 'electra.encoder.layer.5.attention.self.query.bias', 'electra.encoder.layer.11.attention.output.dense.weight', 'electra.encoder.layer.10.intermediate.dense.bias', 'electra.encoder.layer.1.output.LayerNorm.weight', 'discriminator_predictions.dense.bias', 'electra.encoder.layer.0.attention.self.query.bias', 'electra.encoder.layer.5.attention.output.dense.bias', 'electra.encoder.layer.2.output.LayerNorm.weight', 'electra.encoder.layer.4.output.LayerNorm.weight', 'electra.encoder.layer.9.attention.output.dense.weight', 'electra.encoder.layer.4.attention.output.LayerNorm.bias', 'electra.encoder.layer.8.attention.output.dense.bias', 'electra.encoder.layer.1.intermediate.dense.weight', 'electra.encoder.layer.8.attention.self.query.weight', 'electra.encoder.layer.0.attention.output.LayerNorm.bias', 'electra.encoder.layer.10.attention.self.query.weight', 'electra.encoder.layer.2.attention.self.key.bias', 'electra.encoder.layer.4.output.dense.weight', 'electra.encoder.layer.6.output.LayerNorm.weight', 'electra.encoder.layer.2.attention.self.value.weight', 'electra.encoder.layer.8.attention.self.key.bias', 'electra.encoder.layer.1.output.LayerNorm.bias', 'electra.encoder.layer.8.intermediate.dense.bias', 'electra.encoder.layer.3.output.LayerNorm.weight', 'electra.encoder.layer.9.attention.self.query.weight', 'electra.encoder.layer.5.intermediate.dense.weight', 'electra.encoder.layer.7.attention.self.key.weight', 'electra.encoder.layer.10.attention.self.value.weight', 'electra.encoder.layer.10.attention.self.query.bias', 'electra.encoder.layer.4.attention.self.query.weight', 'electra.encoder.layer.3.attention.output.dense.weight', 'discriminator_predictions.dense_prediction.bias', 'electra.encoder.layer.11.output.LayerNorm.bias', 'electra.encoder.layer.6.attention.self.value.weight', 'electra.encoder.layer.0.attention.self.query.weight', 'electra.encoder.layer.11.output.dense.bias', 'electra.encoder.layer.3.output.LayerNorm.bias', 'electra.encoder.layer.10.intermediate.dense.weight', 'electra.encoder.layer.8.output.dense.bias', 'electra.encoder.layer.8.attention.self.value.weight', 'electra.encoder.layer.11.output.dense.weight', 'electra.encoder.layer.7.intermediate.dense.weight', 'electra.encoder.layer.11.attention.self.query.weight', 'electra.encoder.layer.11.attention.output.LayerNorm.bias', 'electra.encoder.layer.6.attention.self.key.weight', 'electra.encoder.layer.4.attention.self.key.bias', 'electra.encoder.layer.9.output.dense.bias', 'electra.encoder.layer.4.attention.self.value.weight', 'electra.encoder.layer.3.attention.output.LayerNorm.weight', 'electra.encoder.layer.1.attention.self.key.bias', 'electra.encoder.layer.7.attention.output.dense.bias', 'electra.encoder.layer.0.output.LayerNorm.weight', 'electra.encoder.layer.11.attention.self.value.weight', 'electra.encoder.layer.11.attention.self.key.weight', 'electra.encoder.layer.0.attention.output.dense.bias', 'electra.encoder.layer.8.attention.output.LayerNorm.bias', 'electra.encoder.layer.11.attention.self.key.bias', 'electra.encoder.layer.1.attention.output.LayerNorm.bias', 'electra.encoder.layer.10.attention.output.dense.bias', 'electra.encoder.layer.1.attention.output.LayerNorm.weight', 'electra.encoder.layer.11.intermediate.dense.weight', 'electra.encoder.layer.3.attention.output.LayerNorm.bias', 'electra.encoder.layer.10.attention.output.dense.weight', 'electra.encoder.layer.1.output.dense.bias', 'electra.encoder.layer.6.output.dense.weight', 'electra.encoder.layer.9.attention.output.LayerNorm.weight', 'electra.encoder.layer.3.output.dense.bias', 'electra.encoder.layer.2.attention.self.key.weight', 'electra.encoder.layer.5.attention.self.value.bias', 'electra.encoder.layer.2.attention.self.value.bias', 'electra.encoder.layer.2.attention.output.dense.bias', 'electra.encoder.layer.6.attention.self.key.bias', 'electra.encoder.layer.8.attention.self.query.bias', 'electra.encoder.layer.9.output.LayerNorm.weight', 'electra.encoder.layer.9.attention.self.query.bias', 'electra.encoder.layer.1.attention.self.value.bias', 'electra.encoder.layer.4.intermediate.dense.bias', 'electra.encoder.layer.3.intermediate.dense.bias', 'electra.encoder.layer.2.attention.self.query.bias', 'electra.encoder.layer.5.attention.self.key.bias', 'electra.embeddings_project.weight', 'electra.encoder.layer.6.attention.self.query.weight', 'electra.encoder.layer.6.output.dense.bias', 'electra.encoder.layer.6.output.LayerNorm.bias', 'electra.encoder.layer.7.intermediate.dense.bias', 'electra.encoder.layer.0.attention.self.value.weight', 'electra.encoder.layer.7.attention.output.LayerNorm.bias', 'electra.encoder.layer.7.output.dense.weight', 'electra.encoder.layer.10.attention.self.key.bias', 'electra.encoder.layer.0.output.dense.bias', 'electra.encoder.layer.4.attention.self.key.weight', 'electra.encoder.layer.4.attention.output.dense.weight', 'electra.embeddings.LayerNorm.bias', 'electra.encoder.layer.8.attention.output.LayerNorm.weight', 'electra.encoder.layer.6.attention.output.dense.weight', 'electra.encoder.layer.7.attention.self.query.bias', 'electra.encoder.layer.11.attention.self.value.bias', 'electra.encoder.layer.3.intermediate.dense.weight', 'electra.encoder.layer.4.intermediate.dense.weight', 'electra.embeddings.position_embeddings.weight', 'electra.encoder.layer.5.attention.output.LayerNorm.weight', 'electra.encoder.layer.8.attention.self.value.bias', 'electra.encoder.layer.0.intermediate.dense.bias', 'electra.encoder.layer.4.attention.self.query.bias', 'electra.encoder.layer.2.output.LayerNorm.bias', 'electra.encoder.layer.8.output.LayerNorm.bias', 'electra.encoder.layer.11.attention.self.query.bias', 'electra.encoder.layer.4.output.LayerNorm.bias', 'electra.encoder.layer.11.attention.output.dense.bias', 'electra.encoder.layer.3.attention.self.value.weight', 'electra.encoder.layer.7.attention.self.query.weight', 'electra.encoder.layer.1.attention.output.dense.weight', 'electra.encoder.layer.5.attention.output.LayerNorm.bias', 'electra.encoder.layer.8.attention.self.key.weight', 'electra.embeddings.word_embeddings.weight', 'electra.encoder.layer.8.output.dense.weight', 'electra.encoder.layer.5.attention.self.value.weight', 'electra.encoder.layer.0.attention.output.LayerNorm.weight', 'electra.encoder.layer.1.attention.output.dense.bias', 'electra.encoder.layer.4.output.dense.bias', 'electra.encoder.layer.7.attention.self.value.weight', 'electra.encoder.layer.6.intermediate.dense.weight', 'discriminator_predictions.dense.weight', 'electra.encoder.layer.5.output.LayerNorm.bias', 'electra.encoder.layer.0.attention.output.dense.weight', 'electra.encoder.layer.11.attention.output.LayerNorm.weight', 'electra.encoder.layer.11.output.LayerNorm.weight', 'electra.encoder.layer.11.intermediate.dense.bias', 'electra.encoder.layer.9.attention.output.LayerNorm.bias', 'electra.encoder.layer.10.attention.output.LayerNorm.bias', 'electra.encoder.layer.10.output.dense.weight']
- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of XLMRobertaModel were not initialized from the model checkpoint at monologg/koelectra-small-v2-discriminator and are newly initialized: ['encoder.layer.10.attention.output.dense.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'pooler.dense.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.8.attention.self.value.bias', 'embeddings.LayerNorm.bias', 'pooler.dense.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.9.attention.self.value.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.6.output.dense.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.7.intermediate.dense.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.key.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.11.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.attention.self.key.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Traceback (most recent call last):
  File "/home/nlplab/Devlopment/2022_korean_AI/JiWoo/BASELINE/koBERT/sentiment_analysis.py", line 739, in <module>
    test_sentiment_analysis()
  File "/home/nlplab/Devlopment/2022_korean_AI/JiWoo/BASELINE/koBERT/sentiment_analysis.py", line 697, in test_sentiment_analysis
    model.load_state_dict(torch.load(entity_property_model_path, map_location=device))
  File "/home/nlplab/anaconda3/envs/jiwoo/lib/python3.10/site-packages/torch/serialization.py", line 699, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/nlplab/anaconda3/envs/jiwoo/lib/python3.10/site-packages/torch/serialization.py", line 230, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/nlplab/anaconda3/envs/jiwoo/lib/python3.10/site-packages/torch/serialization.py", line 211, in __init__
    super(_open_file, self).__init__(open(name, mode))
IsADirectoryError: [Errno 21] Is a directory: './saved_models/default_path/'